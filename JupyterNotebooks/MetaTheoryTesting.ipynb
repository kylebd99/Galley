{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uniform_fiber (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Finch\n",
    "using SparseArrays\n",
    "using Metatheory\n",
    "using Metatheory.EGraphs\n",
    "using TermInterface\n",
    "using PrettyPrinting\n",
    "include(\"../Source/Spartan.jl\")\n",
    "include(\"../Source/UtilityFuncs.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expression: Reorder(\n",
      "   ReduceDim(+,[\"l\"],\n",
      "      MapJoin(*,\n",
      "         MapJoin(*,\n",
      "            InputTensor(A,[\"i\", \"j\"],FIBER,Any[\"i\", \"j\", \"l\"]),\n",
      "            InputTensor(B,[\"j\", \"l\"],FIBER,Any[\"i\", \"j\", \"l\"])),\n",
      "         InputTensor(C,[\"j\", \"l\"],FIBER,Any[\"i\", \"j\", \"l\"]))),[\"j\", \"i\"])\n",
      "Time to Execute: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47436554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Expression: Reorder(\n",
      "   ReduceDim(+,[\"l\"],\n",
      "      MapJoin(*,\n",
      "         MapJoin(*,\n",
      "            InputTensor(B,[\"j\", \"l\"],FIBER,[\"i\", \"j\", \"l\"]),\n",
      "            InputTensor(C,[\"j\", \"l\"],FIBER,[\"i\", \"j\", \"l\"])),\n",
      "         InputTensor(A,[\"i\", \"j\"],FIBER,[\"i\", \"j\", \"l\"]))),[\"j\", \"i\"])\n",
      "Time to Execute: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.098742641\n",
      "Optimized Expression: ReduceDim(+,[\"l\"],\n",
      "   MapJoin(*,\n",
      "      MapJoin(*,\n",
      "         Reorder(\n",
      "            InputTensor(B,[\"j\", \"l\"],FIBER,[\"l\", \"j\", \"i\"]),[\"l\", \"j\", \"i\"]),\n",
      "         Reorder(\n",
      "            InputTensor(C,[\"j\", \"l\"],FIBER,[\"l\", \"j\", \"i\"]),[\"l\", \"j\", \"i\"])),\n",
      "      Reorder(\n",
      "         InputTensor(A,[\"i\", \"j\"],FIBER,[\"l\", \"j\", \"i\"]),[\"l\", \"j\", \"i\"])))\n",
      "Time to Execute: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.152786531\n",
      "Optimized Expression: ReduceDim(+,[\"l\"],\n",
      "   MapJoin(*,\n",
      "      MapJoin(*,\n",
      "         InputTensor(B,[\"j\", \"l\"],FIBER,[\"j\", \"l\", \"i\"]),\n",
      "         InputTensor(C,[\"j\", \"l\"],FIBER,[\"j\", \"l\", \"i\"])),\n",
      "      Reorder(\n",
      "         InputTensor(A,[\"i\", \"j\"],FIBER,[\"j\", \"l\", \"i\"]),[\"j\", \"l\", \"i\"])))\n",
      "Time to Execute: 0.080366201\n",
      "Optimized Expression: Reorder(\n",
      "   ReduceDim(+,[\"l\"],\n",
      "      MapJoin(*,\n",
      "         MapJoin(*,\n",
      "            Reorder(\n",
      "               InputTensor(B,[\"j\", \"l\"],FIBER,[\"i\", \"l\", \"j\"]),[\"i\", \"l\", \"j\"]),\n",
      "            Reorder(\n",
      "               InputTensor(C,[\"j\", \"l\"],FIBER,[\"i\", \"l\", \"j\"]),[\"i\", \"l\", \"j\"])),\n",
      "         InputTensor(A,[\"i\", \"j\"],FIBER,[\"i\", \"l\", \"j\"]))),[\"j\", \"i\"])\n",
      "Time to Execute: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.075239145\n",
      "Is Correct?: true\n"
     ]
    }
   ],
   "source": [
    "is = [\"i\", \"l\"]\n",
    "A = InputTensor(\"A\", [\"i\", \"j\"], uniform_fiber([10000, 100], .01))\n",
    "B = InputTensor(\"B\", [\"j\", \"l\"], uniform_fiber([100, 10000], .01))\n",
    "C = InputTensor(\"C\", [\"j\", \"l\"], uniform_fiber([100, 10000], .01))\n",
    "output_order = [\"j\", \"i\"]\n",
    "\n",
    "verbose = 1\n",
    "# Sum_i Sum_l B[j,l]*A[i,j]*A[i,j]\n",
    "D = A * B * C\n",
    "E = Reorder(ReduceDim(+, [\"l\"],  D), [\"j\",\"i\"])\n",
    ":(MapJoin($*, $A, MapJoin($*, $B, $C)))\n",
    "\n",
    "output_tensor_1 = spartan(E, verbose=verbose, optimize=false)\n",
    "#println(output_tensor)\n",
    "\n",
    "global_index_order = [\"i\", \"j\", \"l\"]\n",
    "# (Sum_l B[j,l])*(Sum_i A[i,j] * A[i,j])\n",
    "output_tensor_2 = spartan(E, verbose=verbose, global_index_order = global_index_order, optimize=true)\n",
    "\n",
    "global_index_order = [\"l\", \"j\", \"i\"]\n",
    "output_tensor_3 = spartan(E, verbose=verbose, global_index_order = global_index_order, optimize=true)\n",
    "\n",
    "global_index_order = [\"j\", \"l\", \"i\"]\n",
    "output_tensor_4 = spartan(E, verbose=verbose, global_index_order = global_index_order, optimize=true)\n",
    "\n",
    "\n",
    "global_index_order = [\"i\", \"l\", \"j\"]\n",
    "output_tensor_5 = spartan(E, verbose=verbose, global_index_order = global_index_order, optimize=true)\n",
    "\n",
    "println(\"Is Correct?: \", output_tensor_1 == output_tensor_2 && output_tensor_2 == output_tensor_3 && \n",
    "                                output_tensor_3 == output_tensor_4 && output_tensor_4 == output_tensor_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expression: ReduceDim(+,[\"i\", \"j\"],\n",
      "   MapJoin(*,\n",
      "      InputTensor(B,[\"i\", \"k\", \"l\"],FIBER,Any[\"i\", \"j\", \"k\", \"l\"]),\n",
      "      MapJoin(*,\n",
      "         Reorder(\n",
      "            InputTensor(C,[\"k\", \"j\"],FIBER,Any[\"i\", \"j\", \"k\", \"l\"]),Any[\"i\", \"j\", \"k\", \"l\"]),\n",
      "         Reorder(\n",
      "            InputTensor(D,[\"l\", \"j\"],FIBER,Any[\"i\", \"j\", \"k\", \"l\"]),Any[\"i\", \"j\", \"k\", \"l\"]))))\n",
      "1"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "Kernel: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReorderExpr([\"i\", \"j\", \"k\", \"l\"], InputExpr"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"A\", [\"l\", \"j\"], AccessProtocol[t_walk, t_walk], TensorStats([\"l\", \"j\"], Dict"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"j\" => 1000, \"l\" => 1000), 100362.0, 0, Any[\"i\", \"j\", \"k\", \"l\"])))\n",
      "Output Order: [\"j\", \"l\"]\n",
      "Loop Order: [\"l\", \"j\"]\n",
      "Expected Output Tensor Size: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100362.0\n",
      "Output Tensor Size: 100362\n",
      "4\n",
      "4\n",
      "Kernel: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReorderExpr([\"i\", \"j\", \"k\", \"l\"], InputExpr(\"A\", [\"k\", \"j\"], AccessProtocol[t_walk, t_walk], TensorStats([\"k\", \"j\"], Dict(\"k\" => 1000, \"j\" => 1000), 99717.0, 0, Any[\"i\", \"j\", \"k\", \"l\"])))\n",
      "Output Order: [\"j\", \"k\"]\n",
      "Loop Order: [\"k\", \"j\"]\n",
      "Expected Output Tensor Size: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99717.0\n",
      "Output Tensor Size: 99717\n",
      "3\n",
      "Kernel: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OperatorExpr(*, "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InputExpr[InputExpr(\"A\", [\"j\", \"k\"], AccessProtocol[t_walk, t_walk], TensorStats([\"j\", \"k\"], Dict(\"k\" => 1000, \"j\" => 1000), 99717.0, 0, [\"i\", \"j\", \"k\", \"l\"])), InputExpr(\"B\", [\"j\", \"l\"], AccessProtocol[t_walk, t_walk], TensorStats([\"j\", \"l\"], Dict(\"j\" => 1000, \"l\" => 1000), 100362.0, 0, [\"i\", \"j\", \"k\", \"l\"]))])\n",
      "Output Order: [\"j\", \"k\", \"l\"]\n",
      "Loop Order: [\"l\", \"k\", \"j\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Output Tensor Size: 1.0007797554000001e7\n",
      "Output Tensor Size: 10009198\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: OperatorExpr(*, InputExpr[InputExpr(\"A\", [\"i\", \"k\", \"l\"], AccessProtocol[t_walk, t_walk, t_walk], TensorStats([\"i\", \"k\", \"l\"], Dict(\"k\" => 1000, \"l\" => 1000, \"i\" => 1000), 9974.0, 0, Any[\"i\", \"j\", \"k\", \"l\"])), InputExpr(\"B\", [\"j\", \"k\", \"l\"], AccessProtocol[t_walk, t_walk, t_walk], TensorStats([\"j\", \"k\", \"l\"], Dict(\"j\" => 1000, \"k\" => 1000, \"l\" => 1000), 1.0007797554000001e7, 0, [\"i\", \"j\", \"k\", \"l\"]))])\n",
      "Output Order: [\"i\", \"j\", \"k\", \"l\"]\n",
      "Loop Order: [\"l\", \"k\", \"j\", \"i\"]\n",
      "Expected Output Tensor Size: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99817.772803596\n",
      "Output Tensor Size: 99761\n",
      "1\n",
      "Kernel: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AggregateExpr(+, [\"i\", \"j\"], InputExpr(\"A\", [\"i\", \"j\", \"k\", \"l\"], AccessProtocol[t_walk, t_walk, t_walk, t_walk], TensorStats([\"i\", \"j\", \"k\", \"l\"], Dict(\"j\" => 1000, \"k\" => 1000, \"l\" => 1000, \"i\" => 1000), 99817.772803596, 0, Any[\"i\", \"j\", \"k\", \"l\"])))\n",
      "Output Order: [\"k\", \"l\"]\n",
      "Loop Order: [\"l\", \"k\", \"j\", \"i\"]\n",
      "Expected Output Tensor Size: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94997.68548186404\n",
      "Output Tensor Size: 9933\n",
      "Time to Execute: 14.066471382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SaturationReport\n",
      "=================\n",
      "\tStop Reason: saturated\n",
      "\tIterations: 7\n",
      "\tEGraph Size: 32 eclasses, 74 nodes\n",
      "\u001b[0m\u001b[1m ────────────────────────────────────────────────────────────────────\u001b[22m\n",
      "\u001b[0m\u001b[1m                   \u001b[22m         Time                    Allocations      \n",
      "                   ───────────────────────   ────────────────────────\n",
      " Tot / % measured:      128ms /  99.9%           7.98MiB /  99.9%    \n",
      "\n",
      " Section   ncalls     time    %tot     avg     alloc    %tot      avg\n",
      " ────────────────────────────────────────────────────────────────────\n",
      " Apply          7   92.6ms   72.7%  13.2ms   5.66MiB   71.1%   829KiB\n",
      " Search         7   28.3ms   22.2%  4.05ms   2.02MiB   25.4%   296KiB\n",
      "   1            7   25.7ms   20.2%  3.67ms    364KiB    4.5%  51.9KiB\n",
      "   5            7    275μs    0.2%  39.3μs    223KiB    2.7%  31.9KiB\n",
      "   6            7    267μs    0.2%  38.1μs    164KiB    2.0%  23.4KiB\n",
      "   14           7    257μs    0.2%  36.7μs    159KiB    2.0%  22.8KiB\n",
      "   4            7    237μs    0.2%  33.9μs    116KiB    1.4%  16.6KiB\n",
      "   9            7    235μs    0.2%  33.6μs    172KiB    2.1%  24.6KiB\n",
      "   11           7    232μs    0.2%  33.1μs    195KiB    2.4%  27.9KiB\n",
      "   3            7    210μs    0.2%  30.0μs    126KiB    1.5%  18.0KiB\n",
      "   12           7    201μs    0.2%  28.7μs    144KiB    1.8%  20.6KiB\n",
      "   8            7    171μs    0.1%  24.5μs    134KiB    1.6%  19.1KiB\n",
      "   10           7    160μs    0.1%  22.9μs    108KiB    1.3%  15.4KiB\n",
      "   7            7    116μs    0.1%  16.6μs   53.3KiB    0.7%  7.61KiB\n",
      "   2            7    104μs    0.1%  14.9μs   45.7KiB    0.6%  6.53KiB\n",
      "   13           7   85.8μs    0.1%  12.3μs   44.7KiB    0.5%  6.39KiB\n",
      " Rebuild        7   6.49ms    5.1%   928μs    290KiB    3.5%  41.4KiB\n",
      "\u001b[0m\u001b[1m ────────────────────────────────────────────────────────────────────\u001b[22m\n",
      "\n",
      "Optimized Expression: ReduceDim(+,[\"i\", \"j\"],\n",
      "   MapJoin(*,\n",
      "      MapJoin(*,\n",
      "         Reorder(\n",
      "            InputTensor(C,[\"k\", \"j\"],FIBER,Any[\"i\", \"j\", \"k\", \"l\"]),Any[\"i\", \"j\", \"k\", \"l\"]),\n",
      "         InputTensor(B,[\"i\", \"k\", \"l\"],FIBER,Any[\"i\", \"j\", \"k\", \"l\"])),\n",
      "      Reorder(\n",
      "         InputTensor(D,[\"l\", \"j\"],FIBER,Any[\"i\", \"j\", \"k\", \"l\"]),Any[\"i\", \"j\", \"k\", \"l\"])))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "3\n",
      "Kernel: ReorderExpr([\"i\", \"j\", \"k\", \"l\"], InputExpr(\"A\", [\"l\", \"j\"], AccessProtocol[t_walk, t_walk], TensorStats([\"l\", \"j\"], Dict(\"j\" => 1000, \"l\" => 1000), 100362.0, 0, Any[\"i\", \"j\", \"k\", \"l\"])))\n",
      "Output Order: [\"j\", \"l\"]\n",
      "Loop Order: [\"l\", \"j\"]\n",
      "Expected Output Tensor Size: 100362.0\n",
      "Output Tensor Size: 100362\n",
      "3\n",
      "4\n",
      "4\n",
      "Kernel: ReorderExpr([\"i\", \"j\", \"k\", \"l\"], InputExpr(\"A\", [\"k\", \"j\"], AccessProtocol[t_walk, t_walk], TensorStats([\"k\", \"j\"], Dict(\"k\" => 1000, \"j\" => 1000), 99717.0, 0, Any[\"i\", \"j\", \"k\", \"l\"])))\n",
      "Output Order: [\"j\", \"k\"]\n",
      "Loop Order: [\"k\", \"j\"]\n",
      "Expected Output Tensor Size: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99717.0\n",
      "Output Tensor Size: 99717\n",
      "3\n",
      "Kernel: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OperatorExpr(*, InputExpr[InputExpr(\"A\", [\"j\", \"k\"], AccessProtocol[t_walk, t_walk], TensorStats([\"j\", \"k\"], Dict(\"k\" => 1000, \"j\" => 1000), 99717.0, 0, [\"i\", \"j\", \"k\", \"l\"])), InputExpr(\"B\", [\"i\", \"k\", \"l\"], AccessProtocol[t_walk, t_walk, t_walk], TensorStats([\"i\", \"k\", \"l\"], Dict(\"k\" => 1000, \"l\" => 1000, \"i\" => 1000), 9974.0, 0, Any[\"i\", \"j\", \"k\", \"l\"]))])\n",
      "Output Order: [\"i\", \"j\", \"k\", \"l\"]\n",
      "Loop Order: [\"l\", \"k\", \"j\", \"i\"]\n",
      "Expected Output Tensor Size: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "994577.358\n",
      "Output Tensor Size: 996312\n",
      "2\n",
      "Kernel: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OperatorExpr(*, InputExpr[InputExpr(\"A\", [\"i\", \"j\", \"k\", \"l\"], AccessProtocol[t_walk, t_walk, t_walk, t_walk], TensorStats([\"i\", \"j\", \"k\", \"l\"], Dict(\"j\" => 1000, \"k\" => 1000, \"l\" => 1000, \"i\" => 1000), 994577.358, 0, [\"i\", \"j\", \"k\", \"l\"])), InputExpr(\"B\", [\"j\", \"l\"], AccessProtocol[t_walk, t_walk], TensorStats([\"j\", \"l\"], Dict(\"j\" => 1000, \"l\" => 1000), 100362.0, 0, [\"i\", \"j\", \"k\", \"l\"]))])\n",
      "Output Order: [\"i\", \"j\", \"k\", \"l\"]\n",
      "Loop Order: [\"l\", \"k\", \"j\", \"i\"]\n",
      "Expected Output Tensor Size: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99817.772803596\n",
      "Output Tensor Size: 99761\n",
      "1\n",
      "Kernel: AggregateExpr(+, [\"i\", \"j\"], InputExpr(\"A\", [\"i\", \"j\", \"k\", \"l\"], AccessProtocol[t_walk, t_walk, t_walk, t_walk], TensorStats([\"i\", \"j\", \"k\", \"l\"], Dict(\"j\" => 1000, \"k\" => 1000, \"l\" => 1000, \"i\" => 1000), 99817.772803596, 0, [\"i\", \"j\", \"k\", \"l\"])))\n",
      "Output Order: [\"k\", \"l\"]\n",
      "Loop Order: [\"l\", \"k\", \"j\", \"i\"]\n",
      "Expected Output Tensor Size: 94997.68548186404\n",
      "Output Tensor Size: 9933\n",
      "Time to Execute: 3.853391465\n",
      "Expression: ReduceDim(+,[\"i\"],\n",
      "   MapJoin(*,\n",
      "      InputTensor(B,[\"i\", \"k\", \"l\"],FIBER,Any[\"i\", \"j\", \"k\", \"l\"]),\n",
      "      ReduceDim(+,[\"j\"],\n",
      "         MapJoin(*,\n",
      "            Reorder(\n",
      "               InputTensor(C,[\"k\", \"j\"],FIBER,Any[\"i\", \"j\", \"k\", \"l\"]),Any[\"i\", \"j\", \"k\", \"l\"]),\n",
      "            Reorder(\n",
      "               InputTensor(D,[\"l\", \"j\"],FIBER,Any[\"i\", \"j\", \"k\", \"l\"]),Any[\"i\", \"j\", \"k\", \"l\"])))))\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "5\n",
      "Kernel: ReorderExpr([\"i\", \"j\", \"k\", \"l\"], InputExpr(\"A\", [\"l\", \"j\"], AccessProtocol[t_walk, t_walk], TensorStats([\"l\", \"j\"], Dict(\"j\" => 1000, \"l\" => 1000), 100362.0, 0, Any[\"i\", \"j\", \"k\", \"l\"])))\n",
      "Output Order: [\"j\", \"l\"]\n",
      "Loop Order: [\"l\", \"j\"]\n",
      "Expected Output Tensor Size: 100362.0\n",
      "Output Tensor Size: 100362\n",
      "5\n",
      "5\n",
      "Kernel: ReorderExpr([\"i\", \"j\", \"k\", \"l\"], InputExpr(\"A\", [\"k\", \"j\"], AccessProtocol[t_walk, t_walk], TensorStats([\"k\", \"j\"], Dict(\"k\" => 1000, \"j\" => 1000), 99717.0, 0, Any[\"i\", \"j\", \"k\", \"l\"])))\n",
      "Output Order: [\"j\", \"k\"]\n",
      "Loop Order: [\"k\", \"j\"]\n",
      "Expected Output Tensor Size: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99717.0\n",
      "Output Tensor Size: 99717\n",
      "4\n",
      "Kernel: OperatorExpr(*, InputExpr[InputExpr(\"A\", [\"j\", \"k\"], AccessProtocol[t_walk, t_walk], TensorStats([\"j\", \"k\"], Dict(\"k\" => 1000, \"j\" => 1000), 99717.0, 0, [\"i\", \"j\", \"k\", \"l\"])), InputExpr(\"B\", [\"j\", \"l\"], AccessProtocol[t_walk, t_walk], TensorStats([\"j\", \"l\"], Dict(\"j\" => 1000, \"l\" => 1000), 100362.0, 0, [\"i\", \"j\", \"k\", \"l\"]))])\n",
      "Output Order: [\"j\", \"k\", \"l\"]\n",
      "Loop Order: [\"l\", \"k\", \"j\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Output Tensor Size: 1.0007797554000001e7\n",
      "Output Tensor Size: 10009198\n",
      "3\n",
      "Kernel: AggregateExpr(+, [\"j\"], InputExpr(\"A\", [\"j\", \"k\", \"l\"], AccessProtocol[t_walk, t_walk, t_walk], TensorStats([\"j\", \"k\", \"l\"], Dict(\"j\" => 1000, \"k\" => 1000, \"l\" => 1000), 1.0007797554000001e7, 0, [\"i\", \"j\", \"k\", \"l\"])))\n",
      "Output Order: [\"k\", \"l\"]\n",
      "Loop Order: [\"l\", \"k\", \"j\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Output Tensor Size: 999957.1674487703\n",
      "Output Tensor Size: 999960\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: OperatorExpr(*, InputExpr[InputExpr(\"A\", [\"i\", \"k\", \"l\"], AccessProtocol[t_walk, t_walk, t_walk], TensorStats([\"i\", \"k\", \"l\"], Dict(\"k\" => 1000, \"l\" => 1000, \"i\" => 1000), 9974.0, 0, Any[\"i\", \"j\", \"k\", \"l\"])), InputExpr(\"B\", [\"k\", \"l\"], AccessProtocol[t_walk, t_walk], TensorStats([\"k\", \"l\"], Dict(\"k\" => 1000, \"l\" => 1000), 999957.1674487703, 0, [\"i\", \"j\", \"k\", \"l\"]))])\n",
      "Output Order: [\"i\", \"k\", \"l\"]\n",
      "Loop Order: [\"l\", \"k\", \"i\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Output Tensor Size: 9973.572788134034\n",
      "Output Tensor Size: 9974\n",
      "1\n",
      "Kernel: AggregateExpr(+, [\"i\"], InputExpr(\"A\", [\"i\", \"k\", \"l\"], AccessProtocol[t_walk, t_walk, t_walk], TensorStats([\"i\", \"k\", \"l\"], Dict(\"k\" => 1000, \"l\" => 1000, \"i\" => 1000), 9973.572788134034, 0, Any[\"i\", \"j\", \"k\", \"l\"])))\n",
      "Output Order: [\"k\", \"l\"]\n",
      "Loop Order: [\"l\", \"k\", \"i\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Output Tensor Size: 9924.050891170322\n",
      "Output Tensor Size: 9933\n",
      "Time to Execute: 6.513719902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SparseHash (0) [:,1:1000]\n",
       "├─[:,1]: SparseHash (0) [1:1000]\n",
       "│ ├─[120]: 10\n",
       "│ ├─[195]: 8\n",
       "│ │ ⋮\n",
       "│ ├─[799]: 13\n",
       "│ ├─[810]: 12\n",
       "├─[:,2]: SparseHash (0) [1:1000]\n",
       "│ ├─[47]: 13\n",
       "│ ├─[164]: 9\n",
       "│ │ ⋮\n",
       "│ ├─[934]: 9\n",
       "│ ├─[948]: 11\n",
       "│ ⋮\n",
       "├─[:,999]: SparseHash (0) [1:1000]\n",
       "│ ├─[104]: 13\n",
       "│ ├─[122]: 5\n",
       "│ │ ⋮\n",
       "│ ├─[715]: 11\n",
       "│ ├─[950]: 15\n",
       "├─[:,1000]: SparseHash (0) [1:1000]\n",
       "│ ├─[46]: 12\n",
       "│ ├─[643]: 9\n",
       "│ ├─[779]: 10\n",
       "│ ├─[786]: 7\n",
       "│ ├─[927]: 9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "is = [\"i\", \"j\"]\n",
    "B = InputTensor(\"B\", [\"i\", \"k\", \"l\"], uniform_fiber([1000, 1000, 1000], .00001))\n",
    "D = InputTensor(\"D\", [\"l\", \"j\"], uniform_fiber([1000, 1000], 0.1))\n",
    "C = InputTensor(\"C\", [\"k\", \"j\"], uniform_fiber([1000, 1000], 0.1))\n",
    "\n",
    "verbose = 3\n",
    "MTTKRP = ReduceDim(+, is, MapJoin(*, B, MapJoin(*, C, D)))\n",
    "\n",
    "output_tensor_1 = spartan(MTTKRP, optimize=false, verbose=verbose)\n",
    "\n",
    "output_tensor_2 = spartan(MTTKRP, optimize=true, verbose=verbose)\n",
    "\n",
    "MTTKRP_hand_opt = ReduceDim(+, [\"i\"], MapJoin(*, B, ReduceDim(+, [\"j\"], MapJoin(*, C, D))))\n",
    "output_tensor_2 = spartan(MTTKRP_hand_opt, optimize=false, verbose=verbose)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expression: ReduceDim(+,[\"i\", \"j\"],\n",
      "   MapJoin(^,\n",
      "      MapJoin(+,\n",
      "         InputTensor(X,[\"i\", \"j\"],FIBER,Any[\"i\", \"j\"]),\n",
      "         MapJoin(*,\n",
      "            InputTensor(u,[\"i\"],FIBER,Any[\"i\", \"j\"]),\n",
      "            InputTensor(v,[\"j\"],FIBER,Any[\"i\", \"j\"]))),2))\n",
      "Time to Execute: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.489146799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Expression: MapJoin(+,\n",
      "   MapJoin(+,\n",
      "      ReduceDim(+,[\"i\"],\n",
      "         MapJoin(*,\n",
      "            InputTensor(u,[\"i\"],FIBER,[\"i\", \"j\"]),\n",
      "            ReduceDim(+,[\"j\"],\n",
      "               MapJoin(*,\n",
      "                  InputTensor(X,[\"i\", \"j\"],FIBER,[\"i\", \"j\"]),\n",
      "                  InputTensor(v,[\"j\"],FIBER,[\"i\", \"j\"]))))),\n",
      "      MapJoin(+,\n",
      "         MapJoin(*,\n",
      "            ReduceDim(+,[\"j\"],\n",
      "               MapJoin(^,\n",
      "                  InputTensor(v,[\"j\"],FIBER,[\"i\", \"j\"]),2)),\n",
      "            ReduceDim(+,[\"i\"],\n",
      "               MapJoin(^,\n",
      "                  InputTensor(u,[\"i\"],FIBER,[\"i\", \"j\"]),2))),\n",
      "         ReduceDim(+,[\"i\"],\n",
      "            MapJoin(*,\n",
      "               InputTensor(u,[\"i\"],FIBER,[\"i\", \"j\"]),\n",
      "               ReduceDim(+,[\"j\"],\n",
      "                  MapJoin(*,\n",
      "                     InputTensor(X,[\"i\", \"j\"],FIBER,[\"i\", \"j\"]),\n",
      "                     InputTensor(v,[\"j\"],FIBER,[\"i\", \"j\"]))))))),\n",
      "   ReduceDim(+,[\"j\", \"i\"],\n",
      "      MapJoin(^,\n",
      "         InputTensor(X,[\"i\", \"j\"],FIBER,[\"i\", \"j\"]),2)))\n",
      "Time to Execute: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.38932886\n",
      "Is Correct?: true\n"
     ]
    }
   ],
   "source": [
    "is = [\"i\", \"j\"]\n",
    "X = InputTensor(\"X\", [\"i\", \"j\"], uniform_fiber([100, 100], .5))\n",
    "u = InputTensor(\"u\", [\"i\"], uniform_fiber([100], 1.0))\n",
    "v = InputTensor(\"v\", [\"j\"], uniform_fiber([100], 1.0))\n",
    "\n",
    "verbose = 1\n",
    "# Sum_i Sum_j (X[i,j]+u[i]*v[j])\n",
    "output_tensor_1 = spartan(ReduceDim(+, is, MapJoin(^, MapJoin(+, X, MapJoin(*, u, v)), 2)), verbose=verbose, optimize=false)\n",
    "\n",
    "# (Sum_i u[i]^2)*(Sum_j v[j]^2) + (Sum_i u[i] * (Sum_j X[i,j] * V[j])) + (Sum_i u[i] * (Sum_j X[i,j] * V[j])) + (Sum_[i,j] X[i,j]^2)\n",
    "output_tensor_2 = spartan(ReduceDim(+, is, MapJoin(^, MapJoin(+, X, MapJoin(*, u, v)), 2)), verbose=verbose, optimize=true)\n",
    "\n",
    "println(\"Is Correct?: \", output_tensor_1 == output_tensor_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `uniform_fiber` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `uniform_fiber` not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/SparseTensorOptimization/JupyterNotebooks/MetaTheoryTesting.ipynb:2"
     ]
    }
   ],
   "source": [
    "is = [\"i\", \"j\", \"k\"]\n",
    "E_fiber = uniform_fiber([1000, 1000], .04)\n",
    "E_1 = InputTensor(\"E\", [\"i\", \"j\"], E_fiber)\n",
    "E_2 = InputTensor(\"E\", [\"j\", \"k\"], E_fiber)\n",
    "E_3 = InputTensor(\"E\", [\"k\", \"l\"], E_fiber)\n",
    "E_4 = InputTensor(\"E\", [\"l\", \"i\"], E_fiber)\n",
    "\n",
    "verbose = 1\n",
    "D = E_1 * E_2 * E_3 * E_4\n",
    "query = ReduceDim(+, is, D)\n",
    "output_1 = spartan(query, verbose=verbose, optimize = false)\n",
    "output_2 = spartan(query, verbose=verbose, optimize = true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `Finch` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `Finch` not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/SparseTensorOptimization/JupyterNotebooks/MetaTheoryTesting.ipynb:8"
     ]
    }
   ],
   "source": [
    "# Suppose you have a network of power nodes and lines. Further, you need to take weather events/outages into account.\n",
    "# The following query provides the total available power at each node.\n",
    "num_nodes = 1000\n",
    "height = 100\n",
    "width = 100\n",
    "\n",
    "# Because we're dealing with positive numbers, the following is true.\n",
    "Finch.isassociative(::Finch.DefaultAlgebra, ::typeof(min)) = true\n",
    "Finch.iscommutative(::Finch.DefaultAlgebra, ::typeof(min)) = true\n",
    "Finch.isannihilator(::Finch.DefaultAlgebra, ::typeof(min), x) = x <= 0\n",
    "\n",
    "transmission_capacity = InputTensor(\"transmission_capacity\", [\"i\", \"j\"], uniform_fiber([num_nodes, num_nodes], 5.0/num_nodes))\n",
    "\n",
    "node_location_data =  uniform_fiber([num_nodes, height, width], 1.0/height/width)\n",
    "node_location = InputTensor(\"node_location\", [\"i\", \"lat\", \"long\"], node_location_data)\n",
    "neighbor_node_location = InputTensor(\"neighbor_node_location\", [\"j\", \"lat2\", \"long2\"], node_location_data)\n",
    "\n",
    "weather_events_data = uniform_fiber([height, width], .01, default_value = 1, non_default_value = 0)\n",
    "weather_events = InputTensor(\"weather_events\", [\"lat\", \"long\"], weather_events_data)\n",
    "neighbor_weather_events = InputTensor(\"neighbor_weather_events\", [\"lat2\", \"long2\"], weather_events_data)\n",
    "\n",
    "outages_data = uniform_fiber([num_nodes], .1, default_value = 1, non_default_value = 0)\n",
    "node_outage_percents = InputTensor(\"node_outage_percents\", [\"i\"], outages_data)\n",
    "neighbor_node_outage_percents = InputTensor(\"neighbor_node_outage_percents\", [\"j\"], outages_data)\n",
    "\n",
    "node_power_data = uniform_fiber([num_nodes], 1.0)\n",
    "node_power = InputTensor(\"node_power\", [\"i\"], node_power_data)\n",
    "neighbor_node_power = InputTensor(\"neighbor_node_power\", [\"j\"], node_power_data)\n",
    "\n",
    "available_power_query = ReduceDim(+, [\"lat\", \"long\"],node_location * weather_events * node_outage_percents * node_power) + \n",
    "                        ReduceDim(+, [\"j\"], min(ReduceDim(+, [\"lat2\", \"long2\"], neighbor_weather_events* neighbor_node_outage_percents \n",
    "                                                                        * neighbor_node_location * neighbor_node_power),\n",
    "                                                             transmission_capacity))\n",
    "\n",
    "verbose = 1\n",
    "total_neighbor_power_1 = spartan(available_power_query, verbose=verbose, optimize=true)\n",
    "\n",
    "total_neighbor_power_2 = spartan(available_power_query, verbose=verbose, optimize=false)\n",
    "\n",
    "println(\"Is Equivalent: \", total_neighbor_power_1 == total_neighbor_power_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.0",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
