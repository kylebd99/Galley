{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "e_class_to_expr_node (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Finch\n",
    "using SparseArrays\n",
    "using Metatheory\n",
    "using Metatheory.EGraphs\n",
    "using TermInterface\n",
    "using PrettyPrinting\n",
    "include(\"../Source/Spartan.jl\")\n",
    "include(\"../Source/UtilityFuncs.jl\")\n",
    "include(\"../Source/LogicalOptimizer.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expression: ReduceDim(+,[\"m\", \"i_1\"],\n",
      "   MapJoin(*,\n",
      "      MapJoin(*,\n",
      "         InputTensor([\"i_1\", \"m\"],FIBER,Any[\"i_1\", \"m\", \"o\"]),\n",
      "         InputTensor([\"m\", \"o\"],FIBER,Any[\"i_1\", \"m\", \"o\"])),\n",
      "      InputTensor([\"m\", \"o\"],FIBER,Any[\"i_1\", \"m\", \"o\"])))\n",
      "Time to Execute: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.470466796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Expression: ReduceDim(+,[\"m\"],\n",
      "   MapJoin(*,\n",
      "      MapJoin(*,\n",
      "         InputTensor([\"m\", \"o\"],FIBER,Any[\"i_1\", \"m\", \"o\"]),\n",
      "         InputTensor([\"m\", \"o\"],FIBER,Any[\"i_1\", \"m\", \"o\"])),\n",
      "      ReduceDim(+,[\"i_1\"],\n",
      "         InputTensor([\"i_1\", \"m\"],FIBER,Any[\"i_1\", \"m\", \"o\"]))))\n",
      "Time to Execute: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.120815877\n",
      "Optimized Expression: ReduceDim(+,[\"m\"],\n",
      "   MapJoin(*,\n",
      "      MapJoin(*,\n",
      "         Reorder(\n",
      "            InputTensor([\"m\", \"o\"],FIBER,Any[\"i_1\", \"o\", \"m\"]),Any[\"i_1\", \"o\", \"m\"]),\n",
      "         Reorder(\n",
      "            InputTensor([\"m\", \"o\"],FIBER,Any[\"i_1\", \"o\", \"m\"]),Any[\"i_1\", \"o\", \"m\"])),\n",
      "      ReduceDim(+,[\"i_1\"],\n",
      "         InputTensor([\"i_1\", \"m\"],FIBER,Any[\"i_1\", \"o\", \"m\"]))))\n",
      "Time to Execute: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.073663869\n",
      "Optimized Expression: ReduceDim(+,[\"m\"],\n",
      "   MapJoin(*,\n",
      "      MapJoin(*,\n",
      "         InputTensor([\"m\", \"o\"],FIBER,Any[\"m\", \"i_1\", \"o\"]),\n",
      "         InputTensor([\"m\", \"o\"],FIBER,Any[\"m\", \"i_1\", \"o\"])),\n",
      "      ReduceDim(+,[\"i_1\"],\n",
      "         Reorder(\n",
      "            InputTensor([\"i_1\", \"m\"],FIBER,Any[\"m\", \"i_1\", \"o\"]),Any[\"m\", \"i_1\", \"o\"]))))\n",
      "Time to Execute: 0.068830812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Expression: ReduceDim(+,[\"m\"],\n",
      "   MapJoin(*,\n",
      "      MapJoin(*,\n",
      "         InputTensor([\"m\", \"o\"],FIBER,Any[\"m\", \"o\", \"i_1\"]),\n",
      "         InputTensor([\"m\", \"o\"],FIBER,Any[\"m\", \"o\", \"i_1\"])),\n",
      "      ReduceDim(+,[\"i_1\"],\n",
      "         Reorder(\n",
      "            InputTensor([\"i_1\", \"m\"],FIBER,Any[\"m\", \"o\", \"i_1\"]),Any[\"m\", \"o\", \"i_1\"]))))\n",
      "Time to Execute: 0.05809527\n",
      "Is Correct?: true\n"
     ]
    }
   ],
   "source": [
    "A = InputTensor(uniform_fiber([10000, 100], .01))\n",
    "B = InputTensor(uniform_fiber([100, 10000], .01))\n",
    "C = InputTensor(uniform_fiber([100, 10000], .01))\n",
    "D = OutTensor()\n",
    "E = OutTensor()\n",
    "\n",
    "verbose = 1\n",
    "# Sum_i Sum_l B[j,l]*A[i,j]*A[i,j]\n",
    "D[\"j\", \"l\"] = ReduceDim(+, [\"i\"], A[\"i\", \"j\"] * B[\"j\",\"l\"] * C[\"j\", \"l\"])\n",
    "E[\"o\"] = ReduceDim(+, [\"m\"],  D[\"m\", \"o\"])\n",
    "\n",
    "output_tensor_1 = spartan(E, verbose=verbose, optimize=false)\n",
    "\n",
    "output_tensor_2 = spartan(E, verbose=verbose, global_index_order = 1, optimize=true)\n",
    "\n",
    "output_tensor_3 = spartan(E, verbose=verbose, global_index_order = 2, optimize=true)\n",
    "\n",
    "output_tensor_4 = spartan(E, verbose=verbose, global_index_order = 3, optimize=true)\n",
    "\n",
    "output_tensor_5 = spartan(E, verbose=verbose, global_index_order = 4, optimize=true)\n",
    "\n",
    "println(\"Is Correct?: \", output_tensor_1 == output_tensor_2 && output_tensor_2 == output_tensor_3 && \n",
    "                                output_tensor_3 == output_tensor_4 && output_tensor_4 == output_tensor_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimized Expression: MapJoin(*,\n",
    "   MapJoin(*,\n",
    "      Reorder(\n",
    "         InputTensor([\"n\", \"o\"],FIBER,[\"o\", \"m\", \"n\"]),[\"o\", \"m\", \"n\"]),\n",
    "      Reorder(\n",
    "         InputTensor([\"n\", \"o\"],FIBER,[\"o\", \"m\", \"n\"]),[\"o\", \"m\", \"n\"])),\n",
    "   ReduceDim(+,[\"m\"],\n",
    "      InputTensor([\"m\", \"n\"],FIBER,[\"o\", \"m\", \"n\"])))\n",
    "\n",
    "\n",
    "Optimized Expression: Reorder(\n",
    "   MapJoin(*,\n",
    "      MapJoin(*,\n",
    "         InputTensor([\"n\", \"o\"],FIBER,[\"n\", \"o\", \"m\"]),\n",
    "         InputTensor([\"n\", \"o\"],FIBER,[\"n\", \"o\", \"m\"])),\n",
    "      ReduceDim(+,[\"m\"],\n",
    "         Reorder(\n",
    "            InputTensor([\"m\", \"n\"],FIBER,[\"n\", \"o\", \"m\"]),[\"n\", \"o\", \"m\"]))),[\"o\", \"n\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseHash (0) [:,1:100]\n",
       "├─[:,1]: SparseHash (0) [1:10000]\n",
       "│ ├─[7212]: 101\n",
       "├─[:,2]: SparseHash (0) [1:10000]\n",
       "│ ├─[1942]: 94\n",
       "│ ⋮\n",
       "├─[:,98]: SparseHash (0) [1:10000]\n",
       "│ ├─[5937]: 90\n",
       "│ ├─[9212]: 90\n",
       "├─[:,100]: SparseHash (0) [1:10000]\n",
       "│ ├─[5517]: 120"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_tensor_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "ename": "InterruptException",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:\n",
      "\n",
      "Stacktrace:\n",
      " [1] (::Finch.SubFiber{SparseHashLevel{1, Tuple{Int64}, Int64, Dict{Tuple{Int64, Tuple{Int64}}, Int64}, SparseHashLevel{1, Tuple{Int64}, Int64, Dict{Tuple{Int64, Tuple{Int64}}, Int64}, ElementLevel{0, Int64}}}, Int64})(::Int64, ::Vararg{Int64})\n",
      "   @ Finch ~/.julia/packages/Finch/dBzsm/src/levels/sparsehashlevels.jl:123\n",
      " [2] (::Fiber{SparseHashLevel{1, Tuple{Int64}, Int64, Dict{Tuple{Int64, Tuple{Int64}}, Int64}, SparseHashLevel{1, Tuple{Int64}, Int64, Dict{Tuple{Int64, Tuple{Int64}}, Int64}, ElementLevel{0, Int64}}}})(::Int64, ::Vararg{Int64})\n",
      "   @ Finch ~/.julia/packages/Finch/dBzsm/src/fibers.jl:290\n",
      " [3] top-level scope\n",
      "   @ ~/SparseTensorOptimization/JupyterNotebooks/MetaTheoryTesting.ipynb:4"
     ]
    }
   ],
   "source": [
    "same = true\n",
    "for i in 1:100\n",
    "    for j in 1:10000\n",
    "        if output_tensor_1(i,j) != output_tensor_2(i,j) || output_tensor_2(i,j) != output_tensor_3(i,j)|| output_tensor_3(i,j) !=  output_tensor_4(i,j) || output_tensor_4(i,j) != output_tensor_5(i,j)        \n",
    "            same = false\n",
    "        end\n",
    "    end\n",
    "end\n",
    "println(same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `MTTKRP` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `MTTKRP` not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/SparseTensorOptimization/JupyterNotebooks/MetaTheoryTesting.ipynb:7"
     ]
    }
   ],
   "source": [
    "is = [\"i\", \"j\"]\n",
    "B = InputTensor(uniform_fiber([1000, 1000, 1000], .00001))\n",
    "D = InputTensor(uniform_fiber([1000, 1000], 0.1))\n",
    "C = InputTensor(uniform_fiber([1000, 1000], 0.1))\n",
    "MTTKRP = OutTensor()\n",
    "MTTKRP_hand_opt = OutTensor()\n",
    "\n",
    "verbose = 1\n",
    "MTTKRP[\"k\", \"l\"] = ReduceDim(+, is,  B[\"i\", \"k\", \"l\"] * C[\"k\", \"j\"] * D[\"l\",\"j\"])\n",
    "\n",
    "output_tensor_1 = spartan(MTTKRP, optimize=false, verbose=verbose)\n",
    "\n",
    "output_tensor_2 = spartan(MTTKRP, optimize=true, verbose=verbose)\n",
    "\n",
    "MTTKRP_hand_opt[\"k\", \"l\"] = ReduceDim(+, [\"i\"],  B[\"i\", \"k\", \"l\"]  * ReduceDim(+, [\"j\"], C[\"k\", \"j\"] *  D[\"l\",\"j\"]))\n",
    "output_tensor_2 = spartan(MTTKRP_hand_opt, optimize=false, verbose=verbose)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expression: ReduceDim(+,[\"i\", \"j\"],\n",
      "   MapJoin(^,\n",
      "      MapJoin(+,\n",
      "         InputTensor(X,[\"i\", \"j\"],FIBER,Any[\"i\", \"j\"]),\n",
      "         MapJoin(*,\n",
      "            InputTensor(u,[\"i\"],FIBER,Any[\"i\", \"j\"]),\n",
      "            InputTensor(v,[\"j\"],FIBER,Any[\"i\", \"j\"]))),2))\n",
      "Time to Execute: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.489146799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Expression: MapJoin(+,\n",
      "   MapJoin(+,\n",
      "      ReduceDim(+,[\"i\"],\n",
      "         MapJoin(*,\n",
      "            InputTensor(u,[\"i\"],FIBER,[\"i\", \"j\"]),\n",
      "            ReduceDim(+,[\"j\"],\n",
      "               MapJoin(*,\n",
      "                  InputTensor(X,[\"i\", \"j\"],FIBER,[\"i\", \"j\"]),\n",
      "                  InputTensor(v,[\"j\"],FIBER,[\"i\", \"j\"]))))),\n",
      "      MapJoin(+,\n",
      "         MapJoin(*,\n",
      "            ReduceDim(+,[\"j\"],\n",
      "               MapJoin(^,\n",
      "                  InputTensor(v,[\"j\"],FIBER,[\"i\", \"j\"]),2)),\n",
      "            ReduceDim(+,[\"i\"],\n",
      "               MapJoin(^,\n",
      "                  InputTensor(u,[\"i\"],FIBER,[\"i\", \"j\"]),2))),\n",
      "         ReduceDim(+,[\"i\"],\n",
      "            MapJoin(*,\n",
      "               InputTensor(u,[\"i\"],FIBER,[\"i\", \"j\"]),\n",
      "               ReduceDim(+,[\"j\"],\n",
      "                  MapJoin(*,\n",
      "                     InputTensor(X,[\"i\", \"j\"],FIBER,[\"i\", \"j\"]),\n",
      "                     InputTensor(v,[\"j\"],FIBER,[\"i\", \"j\"]))))))),\n",
      "   ReduceDim(+,[\"j\", \"i\"],\n",
      "      MapJoin(^,\n",
      "         InputTensor(X,[\"i\", \"j\"],FIBER,[\"i\", \"j\"]),2)))\n",
      "Time to Execute: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.38932886\n",
      "Is Correct?: true\n"
     ]
    }
   ],
   "source": [
    "is = [\"i\", \"j\"]\n",
    "X = InputTensor(\"X\", [\"i\", \"j\"], uniform_fiber([100, 100], .5))\n",
    "u = InputTensor(\"u\", [\"i\"], uniform_fiber([100], 1.0))\n",
    "v = InputTensor(\"v\", [\"j\"], uniform_fiber([100], 1.0))\n",
    "\n",
    "verbose = 1\n",
    "# Sum_i Sum_j (X[i,j]+u[i]*v[j])\n",
    "output_tensor_1 = spartan(ReduceDim(+, is, MapJoin(^, MapJoin(+, X, MapJoin(*, u, v)), 2)), verbose=verbose, optimize=false)\n",
    "\n",
    "# (Sum_i u[i]^2)*(Sum_j v[j]^2) + (Sum_i u[i] * (Sum_j X[i,j] * V[j])) + (Sum_i u[i] * (Sum_j X[i,j] * V[j])) + (Sum_[i,j] X[i,j]^2)\n",
    "output_tensor_2 = spartan(ReduceDim(+, is, MapJoin(^, MapJoin(+, X, MapJoin(*, u, v)), 2)), verbose=verbose, optimize=true)\n",
    "\n",
    "println(\"Is Correct?: \", output_tensor_1 == output_tensor_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `uniform_fiber` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `uniform_fiber` not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/SparseTensorOptimization/JupyterNotebooks/MetaTheoryTesting.ipynb:2"
     ]
    }
   ],
   "source": [
    "is = [\"i\", \"j\", \"k\"]\n",
    "E_fiber = uniform_fiber([1000, 1000], .04)\n",
    "E_1 = InputTensor([\"i\", \"j\"], E_fiber)\n",
    "E_2 = InputTensor([\"j\", \"k\"], E_fiber)\n",
    "E_3 = InputTensor([\"k\", \"l\"], E_fiber)\n",
    "E_4 = InputTensor([\"l\", \"i\"], E_fiber)\n",
    "\n",
    "verbose = 1\n",
    "D = E_1 * E_2 * E_3 * E_4\n",
    "query = ReduceDim(+, is, D)\n",
    "output_1 = spartan(query, verbose=verbose, optimize = false)\n",
    "output_2 = spartan(query, verbose=verbose, optimize = true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Expression: MapJoin(+,\n",
      "   ReduceDim(+,[\"j\"],\n",
      "      MapJoin(min,\n",
      "         MapJoin(*,\n",
      "            InputTensor(neighbor_node_outage_percents,[\"j\"],FIBER,Any[\"i\", \"j\", \"lat\", \"lat2\", \"long\", \"long2\"]),\n",
      "            MapJoin(*,\n",
      "               InputTensor(neighbor_node_power,[\"j\"],FIBER,Any[\"i\", \"j\", \"lat\", \"lat2\", \"long\", \"long2\"]),\n",
      "               ReduceDim(+,[\"lat2\", \"long2\"],\n",
      "                  MapJoin(*,\n",
      "                     InputTensor(neighbor_weather_events,[\"lat2\", \"long2\"],FIBER,Any[\"i\", \"j\", \"lat\", \"lat2\", \"long\", \"long2\"]),\n",
      "                     InputTensor(neighbor_node_location,[\"j\", \"lat2\", \"long2\"],FIBER,Any[\"i\", \"j\", \"lat\", \"lat2\", \"long\", \"long2\"]))))),\n",
      "         InputTensor(transmission_capacity,[\"i\", \"j\"],FIBER,Any[\"i\", \"j\", \"lat\", \"lat2\", \"long\", \"long2\"]))),\n",
      "   MapJoin(*,\n",
      "      InputTensor(node_outage_percents,[\"i\"],FIBER,Any[\"i\", \"j\", \"lat\", \"lat2\", \"long\", \"long2\"]),\n",
      "      MapJoin(*,\n",
      "         InputTensor(node_power,[\"i\"],FIBER,Any[\"i\", \"j\", \"lat\", \"lat2\", \"long\", \"long2\"]),\n",
      "         ReduceDim(+,[\"long\", \"lat\"],\n",
      "            MapJoin(*,\n",
      "               InputTensor(weather_events,[\"lat\", \"long\"],FIBER,Any[\"i\", \"j\", \"lat\", \"lat2\", \"long\", \"long2\"]),\n",
      "               InputTensor(node_location,[\"i\", \"lat\", \"long\"],FIBER,Any[\"i\", \"j\", \"lat\", \"lat2\", \"long\", \"long2\"]))))))\n",
      "Time to Execute: 0.002141963\n",
      "Expression: MapJoin(+,\n",
      "   ReduceDim(+,[\"lat\", \"long\"],\n",
      "      MapJoin(*,\n",
      "         MapJoin(*,\n",
      "            MapJoin(*,\n",
      "               InputTensor(node_location,[\"i\", \"lat\", \"long\"],FIBER,Any[\"i\", \"j\", \"lat\", \"lat2\", \"long\", \"long2\"]),\n",
      "               InputTensor(weather_events,[\"lat\", \"long\"],FIBER,Any[\"i\", \"j\", \"lat\", \"lat2\", \"long\", \"long2\"])),\n",
      "            InputTensor(node_outage_percents,[\"i\"],FIBER,Any[\"i\", \"j\", \"lat\", \"lat2\", \"long\", \"long2\"])),\n",
      "         InputTensor(node_power,[\"i\"],FIBER,Any[\"i\", \"j\", \"lat\", \"lat2\", \"long\", \"long2\"]))),\n",
      "   ReduceDim(+,[\"j\"],\n",
      "      MapJoin(min,\n",
      "         ReduceDim(+,[\"lat2\", \"long2\"],\n",
      "            MapJoin(*,\n",
      "               MapJoin(*,\n",
      "                  MapJoin(*,\n",
      "                     InputTensor(neighbor_weather_events,[\"lat2\", \"long2\"],FIBER,Any[\"i\", \"j\", \"lat\", \"lat2\", \"long\", \"long2\"]),\n",
      "                     InputTensor(neighbor_node_outage_percents,[\"j\"],FIBER,Any[\"i\", \"j\", \"lat\", \"lat2\", \"long\", \"long2\"])),\n",
      "                  InputTensor(neighbor_node_location,[\"j\", \"lat2\", \"long2\"],FIBER,Any[\"i\", \"j\", \"lat\", \"lat2\", \"long\", \"long2\"])),\n",
      "               InputTensor(neighbor_node_power,[\"j\"],FIBER,Any[\"i\", \"j\", \"lat\", \"lat2\", \"long\", \"long2\"]))),\n",
      "         InputTensor(transmission_capacity,[\"i\", \"j\"],FIBER,Any[\"i\", \"j\", \"lat\", \"lat2\", \"long\", \"long2\"]))))\n",
      "Time to Execute: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.292272167\n",
      "Is Equivalent: true\n"
     ]
    }
   ],
   "source": [
    "# Suppose you have a network of power nodes and lines. Further, you need to take weather events/outages into account.\n",
    "# The following query provides the total available power at each node.\n",
    "num_nodes = 1000\n",
    "height = 100\n",
    "width = 100\n",
    "\n",
    "# Because we're dealing with positive numbers, the following is true.\n",
    "Finch.isassociative(::Finch.DefaultAlgebra, ::typeof(min)) = true\n",
    "Finch.iscommutative(::Finch.DefaultAlgebra, ::typeof(min)) = true\n",
    "Finch.isannihilator(::Finch.DefaultAlgebra, ::typeof(min), x) = x <= 0\n",
    "\n",
    "transmission_capacity = InputTensor(\"transmission_capacity\", [\"i\", \"j\"], uniform_fiber([num_nodes, num_nodes], 5.0/num_nodes))\n",
    "\n",
    "node_location_data =  uniform_fiber([num_nodes, height, width], 1.0/height/width)\n",
    "node_location = InputTensor(\"node_location\", [\"i\", \"lat\", \"long\"], node_location_data)\n",
    "neighbor_node_location = InputTensor(\"neighbor_node_location\", [\"j\", \"lat2\", \"long2\"], node_location_data)\n",
    "\n",
    "weather_events_data = uniform_fiber([height, width], .01, default_value = 1, non_default_value = 0)\n",
    "weather_events = InputTensor(\"weather_events\", [\"lat\", \"long\"], weather_events_data)\n",
    "neighbor_weather_events = InputTensor(\"neighbor_weather_events\", [\"lat2\", \"long2\"], weather_events_data)\n",
    "\n",
    "outages_data = uniform_fiber([num_nodes], .1, default_value = 1, non_default_value = 0)\n",
    "node_outage_percents = InputTensor(\"node_outage_percents\", [\"i\"], outages_data)\n",
    "neighbor_node_outage_percents = InputTensor(\"neighbor_node_outage_percents\", [\"j\"], outages_data)\n",
    "\n",
    "node_power_data = uniform_fiber([num_nodes], 1.0)\n",
    "node_power = InputTensor(\"node_power\", [\"i\"], node_power_data)\n",
    "neighbor_node_power = InputTensor(\"neighbor_node_power\", [\"j\"], node_power_data)\n",
    "\n",
    "available_power_query = ReduceDim(+, [\"lat\", \"long\"], node_location * weather_events * node_outage_percents * node_power) + \n",
    "                        ReduceDim(+, [\"j\"], min(ReduceDim(+, [\"lat2\", \"long2\"], neighbor_weather_events* neighbor_node_outage_percents \n",
    "                                                                        * neighbor_node_location * neighbor_node_power),\n",
    "                                                             transmission_capacity))\n",
    "\n",
    "verbose = 1\n",
    "total_neighbor_power_1 = spartan(available_power_query, verbose=verbose, optimize=true)\n",
    "\n",
    "total_neighbor_power_2 = spartan(available_power_query, verbose=verbose, optimize=false)\n",
    "\n",
    "println(\"Is Equivalent: \", total_neighbor_power_1 == total_neighbor_power_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.0",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
