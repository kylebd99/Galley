{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spartan (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Finch\n",
    "using SparseArrays\n",
    "using Metatheory\n",
    "using Metatheory.EGraphs\n",
    "using TermInterface\n",
    "using PrettyPrinting\n",
    "include(\"../Source/Spartan.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expression: \n",
      "quote\n",
      "    ReduceDim(\n",
      "        +,\n",
      "        Set([\"i\"]),\n",
      "        ReduceDim(\n",
      "            +,\n",
      "            Set([\"l\"]),\n",
      "            MapJoin(\n",
      "                *,\n",
      "                InputTensor(\"B\", TensorStats(Set([\"j\", \"l\"]), Dict(\"j\" => 1000, \"l\" => 1000), 100000.0, 0.0), nothing),\n",
      "                MapJoin(\n",
      "                    *,\n",
      "                    InputTensor(\"A\", TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 100000.0, 0.0), nothing),\n",
      "                    InputTensor(\"A\", TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 100000.0, 0.0), nothing)))))\n",
      "end\n",
      "Expected Output Tensor Size: 10000.000000000002\n",
      "Output Tensor Size: 95280\n",
      "Expected Output Tensor Size: 1.0000000000000002e6\n",
      "Output Tensor Size: 9075414\n",
      "Expected Output Tensor Size: 632304.5752290363\n",
      "Output Tensor Size: 95280\n",
      "Expected Output Tensor Size: 1000.0\n",
      "Output Tensor Size: 1000\n",
      "Time to Execute: 15.544316994\n",
      "SaturationReport\n",
      "=================\n",
      "\tStop Reason: saturated\n",
      "\tIterations: 6\n",
      "\tEGraph Size: 18 eclasses, 48 nodes\n",
      "\u001b[0m\u001b[1m ────────────────────────────────────────────────────────────────────\u001b[22m\n",
      "\u001b[0m\u001b[1m                   \u001b[22m         Time                    Allocations      \n",
      "                   ───────────────────────   ────────────────────────\n",
      " Tot / % measured:      2.22s /  55.6%            124MiB /  74.2%    \n",
      "\n",
      " Section   ncalls     time    %tot     avg     alloc    %tot      avg\n",
      " ────────────────────────────────────────────────────────────────────\n",
      " Apply          6    533ms   43.2%  88.8ms   34.3MiB   37.5%  5.72MiB\n",
      " Search         6    449ms   36.4%  74.9ms   23.7MiB   25.8%  3.95MiB\n",
      "   1            6    272ms   22.0%  45.3ms   16.4MiB   17.9%  2.74MiB\n",
      "   3            6   48.5ms    3.9%  8.08ms   2.13MiB    2.3%   364KiB\n",
      "   2            6   37.5ms    3.0%  6.25ms   1.09MiB    1.2%   187KiB\n",
      "   5            6   29.0ms    2.4%  4.84ms   1.60MiB    1.7%   273KiB\n",
      "   6            6   24.0ms    1.9%  3.99ms    747KiB    0.8%   124KiB\n",
      "   12           6   15.9ms    1.3%  2.64ms    681KiB    0.7%   113KiB\n",
      "   4            6   14.0ms    1.1%  2.33ms    405KiB    0.4%  67.5KiB\n",
      "   8            6   7.71ms    0.6%  1.29ms    234KiB    0.2%  39.0KiB\n",
      "   9            6    229μs    0.0%  38.2μs    111KiB    0.1%  18.5KiB\n",
      "   11           6    211μs    0.0%  35.1μs    117KiB    0.1%  19.5KiB\n",
      "   10           6    142μs    0.0%  23.6μs   76.9KiB    0.1%  12.8KiB\n",
      "   13           6    109μs    0.0%  18.2μs   35.7KiB    0.0%  5.95KiB\n",
      "   7            6    106μs    0.0%  17.6μs   34.5KiB    0.0%  5.75KiB\n",
      " Rebuild        6    252ms   20.4%  42.1ms   33.7MiB   36.7%  5.61MiB\n",
      "\u001b[0m\u001b[1m ────────────────────────────────────────────────────────────────────\u001b[22m\n",
      "\n",
      "Optimized Expression: \n",
      "quote\n",
      "    MapJoin(\n",
      "        *,\n",
      "        ReduceDim(\n",
      "            +,\n",
      "            Set([\"l\"]),\n",
      "            InputTensor(\"B\", TensorStats(Set([\"j\", \"l\"]), Dict(\"j\" => 1000, \"l\" => 1000), 100000.0, 0.0), MapJoin(*, InputTensor(#= circular reference @-2 =#), MapJoin(*, InputTensor(\"A\", TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 100000.0, 0.0), MapJoin(#= circular reference @-2 =#)), InputTensor(\"A\", TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 100000.0, 0.0), MapJoin(#= circular reference @-2 =#)), TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 10000.000000000002, 0.0), MapJoin(#= circular reference @-2 =#)), TensorStats(Set([\"j\", \"l\", \"i\"]), Dict(\"j\" => 1000, \"l\" => 1000, \"i\" => 1000), 1.0000000000000002e6, 0.0), ReduceDim(+, Set([\"l\"]), MapJoin(#= circular reference @-2 =#), TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 632304.5752290363, 0.0), ReduceDim(+, Set([\"i\"]), ReduceDim(#= circular reference @-2 =#), TensorStats(Set([\"j\"]), Dict(\"j\" => 1000), 1000.0, 0.0), nothing))))),\n",
      "        ReduceDim(\n",
      "            +,\n",
      "            Set([\"i\"]),\n",
      "            MapJoin(\n",
      "                ^,\n",
      "                InputTensor(\"A\", TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 100000.0, 0.0), MapJoin(*, InputTensor(#= circular reference @-2 =#), InputTensor(#= circular reference @-2 =#), TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 10000.000000000002, 0.0), MapJoin(*, InputTensor(\"B\", TensorStats(Set([\"j\", \"l\"]), Dict(\"j\" => 1000, \"l\" => 1000), 100000.0, 0.0), MapJoin(#= circular reference @-2 =#)), MapJoin(#= circular reference @-2 =#), TensorStats(Set([\"j\", \"l\", \"i\"]), Dict(\"j\" => 1000, \"l\" => 1000, \"i\" => 1000), 1.0000000000000002e6, 0.0), ReduceDim(+, Set([\"l\"]), MapJoin(#= circular reference @-2 =#), TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 632304.5752290363, 0.0), ReduceDim(+, Set([\"i\"]), ReduceDim(#= circular reference @-2 =#), TensorStats(Set([\"j\"]), Dict(\"j\" => 1000), 1000.0, 0.0), nothing))))),\n",
      "                2)))\n",
      "end\n",
      "Expected Output Tensor Size: 100000.0\n",
      "Output Tensor Size: 95280\n",
      "Expected Output Tensor Size: 1000.0\n",
      "Output Tensor Size: 1000\n",
      "Expected Output Tensor Size: 1000.0\n",
      "Output Tensor Size: 1000\n",
      "Expected Output Tensor Size: 1000.0\n",
      "Output Tensor Size: 1000\n",
      "Time to Execute: 1.61529508\n",
      "Is Correct?: true\n"
     ]
    }
   ],
   "source": [
    "is = Set([\"i\"])\n",
    "ls = Set([\"l\"])\n",
    "a_N = 100000\n",
    "a_indices = Set([\"i\", \"j\"])\n",
    "a_dimSizes = Dict(\"i\" => 1000, \"j\"=>1000)\n",
    "a = InputTensor(\"A\", TensorStats(a_indices, a_dimSizes, a_N, 0.0))\n",
    "A_fiber = dropdefaults(copyto!(@fiber(sl(sl(e(0.0)))), sparse(rand(1:a_dimSizes[\"i\"], a_N), rand(1:a_dimSizes[\"j\"], a_N), ones(a_N),  a_dimSizes[\"i\"], a_dimSizes[\"j\"]))) # remove zeros\n",
    "b_indices = Set([\"j\", \"l\"])\n",
    "b_dimSizes = Dict(\"j\" => 1000, \"l\" => 1000)\n",
    "b_N = 100000\n",
    "b = InputTensor(\"B\", TensorStats(b_indices, b_dimSizes, b_N, 0.0))\n",
    "B_fiber = dropdefaults(copyto!(@fiber(sl(sl(e(0.0)))), sparse(rand(1:b_dimSizes[\"j\"], b_N),rand(1:b_dimSizes[\"l\"], b_N), ones(b_N),b_dimSizes[\"j\"],  b_dimSizes[\"l\"])))\n",
    "input_tensor_dict = Dict(\"A\" => A_fiber, \"B\" => B_fiber)\n",
    "\n",
    "verbose = 2\n",
    "# Sum_i Sum_l B[j,l]*A[i,j]*A[i,j]\n",
    "output_tensor_1 = spartan(:(ReduceDim($+, $is, ReduceDim($+, $ls, MapJoin($*, $b, MapJoin($*, $a, $a))))), input_tensor_dict, verbose=verbose, optimize=false)\n",
    "#println(output_tensor)\n",
    "\n",
    "# (Sum_l B[j,l])*(Sum_i A[i,j] * A[i,j])\n",
    "output_tensor_2 = spartan(:(ReduceDim($+, $is, ReduceDim($+, $ls, MapJoin($*, $b, MapJoin($*, $a, $a))))), input_tensor_dict, verbose=verbose, optimize=true)\n",
    "#println(output_tensor)\n",
    "\n",
    "println(\"Is Correct?: \", output_tensor_1 == output_tensor_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: TensorStats not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: TensorStats not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[1]:7",
      " [2] eval",
      "   @ ./boot.jl:368 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1428"
     ]
    }
   ],
   "source": [
    "is = Set([\"i\"])\n",
    "js = Set([\"j\"])\n",
    "N = 1000\n",
    "x_N = 1000\n",
    "x_indices = Set([\"i\", \"j\"])\n",
    "x_dimSizes = Dict(\"i\" => N, \"j\"=>N)\n",
    "X = InputTensor(\"X\", TensorStats(x_indices, x_dimSizes, x_N, 0.0))\n",
    "X_fiber = dropdefaults(copyto!(@fiber(sl(sl(e(0.0)))), sparse(rand(1:x_dimSizes[\"j\"], x_N), rand(1:x_dimSizes[\"i\"], x_N), ones(x_N), x_dimSizes[\"j\"], x_dimSizes[\"i\"]))) # remove zeros\n",
    "u_N = N\n",
    "u_indices = Set([\"i\"])\n",
    "u_dimSizes = Dict(\"i\" => N)\n",
    "u = InputTensor(\"u\", TensorStats(u_indices, u_dimSizes, u_dimSizes[\"i\"], 0.0))\n",
    "u_fiber = dropdefaults(copyto!(@fiber(sh{1}(e(0.0))), ones(u_N))) \n",
    "v_N = N\n",
    "v_indices = Set([\"j\"])\n",
    "v_dimSizes = Dict(\"j\" => N)\n",
    "v = InputTensor(\"v\", TensorStats(v_indices, v_dimSizes, v_dimSizes[\"j\"], 0.0))\n",
    "v_fiber = dropdefaults(copyto!(@fiber(sh{1}(e(0.0))), ones(v_N)))\n",
    "input_tensor_dict = Dict(\"X\" => X_fiber, \"u\" => u_fiber, \"v\" => v_fiber)\n",
    "\n",
    "verbose = 2\n",
    "# Sum_i Sum_l B[j,l]*A[i,j]*A[i,j]\n",
    "output_tensor_1 = spartan(:(ReduceDim($+, $is, ReduceDim($+, $js, MapJoin($^, MapJoin($+, $X, MapJoin($*, $u, $v)), 2)))), input_tensor_dict, verbose=verbose, optimize=false)\n",
    "\n",
    "# (Sum_l B[j,l])*(Sum_i A[i,j] * A[i,j])\n",
    "output_tensor_2 = spartan(:(ReduceDim($+, $is, ReduceDim($+, $js, MapJoin($^, MapJoin($+, $X, MapJoin($*, $u, $v)), 2)))), input_tensor_dict, verbose=verbose, optimize=true)\n",
    "\n",
    "println(\"Is Correct?: \", output_tensor_1 == output_tensor_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sequence_instance(declare_instance(variable_instance(:t, t), literal_instance(0)), loop_instance(index_instance(:j), loop_instance(index_instance(:l), loop_instance(index_instance(:i), assign_instance(access_instance(variable_instance(:t, t), updater_instance(create_instance()), index_instance(:l), index_instance(:j)), variable_instance(:+, +), call_instance(variable_instance(:*, *), access_instance(variable_instance(:A_fiber, A_fiber), reader_instance(), index_instance(:i), index_instance(:j)), access_instance(variable_instance(:B_fiber, B_fiber), reader_instance(), index_instance(:j), index_instance(:l))))))))\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Finch\n",
    "t = @fiber(sl(sl(e(0.0))))\n",
    "Finch.@finch_program_instance (t .= 0; @loop j l i t[l, j] += A_fiber[i,j] * B_fiber[j,l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sequence_instance(declare_instance(variable_instance(:C, C), literal_instance(0)), loop_instance(index_instance(:i), loop_instance(index_instance(:j), assign_instance(access_instance(variable_instance(:C, C), updater_instance(create_instance()), index_instance(:j), index_instance(:i)), literal_instance(Finch.FinchNotation.InitWriter{0.0}()), call_instance(variable_instance(:*, *), access_instance(variable_instance(:A_fiber, A_fiber), reader_instance(), index_instance(:j), index_instance(:i)), access_instance(variable_instance(:B_fiber, B_fiber), reader_instance(), index_instance(:j), index_instance(:i)))))))\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = @fiber(sl(sl(e(0.0))))\n",
    "prgm = Finch.@finch_program_instance (C .= 0; @loop i j C[j, i] = A_fiber[j, i] * B_fiber[j, i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: a_dimSizes not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: a_dimSizes not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ some.jl:141",
      " [2] eval",
      "   @ ./boot.jl:368 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1428"
     ]
    }
   ],
   "source": [
    "N=10000\n",
    "A_fiber = dropdefaults(copyto!(@fiber(sl(sl(e(0.0)))), sparse(rand(1:a_dimSizes[\"j\"], N), rand(1:a_dimSizes[\"i\"], N), ones(N), a_dimSizes[\"j\"], a_dimSizes[\"i\"]))) # remove zeros\n",
    "D = @fiber(sl(sl(sl(e(0.0)))))\n",
    "@finch (D.=0; @loop l j i D[i,j,l] = A_fiber[i,j] * A_fiber[j,l])\n",
    "countstored(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(C = Fiber(SparseList{Int64, Int64}(SparseList{Int64, Int64}(SparseList{Int64, Int64}(Element{0.0, Float64}([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]), 10000, [1, 3, 8, 12, 16, 19, 20, 21, 25, 29  …  9861, 9862, 9864, 9866, 9868, 9869, 9870, 9871, 9872, 9873], [419, 6391, 2441, 4892, 6866, 6954, 9064, 1897, 4702, 6455  …  9516, 8842, 9516, 7047, 9014, 5601, 5601, 5601, 7622, 7622]), 10000, [1, 2, 3, 5, 6, 7, 8, 11, 12, 15  …  6232, 6234, 6235, 6236, 6238, 6239, 6241, 6242, 6245, 6247], [5020, 3375, 1821, 5941, 8359, 2837, 9311, 3002, 5799, 8907  …  9465, 2800, 2383, 6452, 1180, 1514, 3318, 4554, 571, 6510]), 10000, [1, 3973], [2, 4, 6, 8, 9, 13, 15, 17, 19, 25  …  9969, 9970, 9974, 9975, 9982, 9983, 9985, 9986, 9998, 10000])),)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = @fiber(sl(sl(sl(e(0.0)))))\n",
    "@finch (C .= 0; @loop  l i j C[i, l, j] = D[i,j,l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = @fiber(sl(sl(e(0.0))))\n",
    "@finch (C .= 0; @loop  j i l C[i,j] += D[i,j,l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is = Set([\"i\"])\n",
    "ks = Set([\"k\"])\n",
    "a_indices = Set([\"i\", \"j\"])\n",
    "a_dimSizes = Dict(\"i\" => 1000, \"j\"=>100)\n",
    "a = InputTensor(TensorStats(a_indices, a_dimSizes, 100000, 0.0), \"A\")\n",
    "b_indices = Set([\"j\", \"k\"])\n",
    "b_dimSizes = Dict(\"j\" => 100, \"k\"=>1000)\n",
    "b = InputTensor(TensorStats(b_indices, b_dimSizes, 100000, 0.0), \"B\")\n",
    "c_indices = Set([\"j\", \"l\"])\n",
    "c_dimSizes = Dict(\"j\" => 100, \"l\" => 100)\n",
    "c = InputTensor(TensorStats(c_indices, c_dimSizes, 10000, 0.0), \"C\")\n",
    "\n",
    "# Sum_i Sum_k C[j,l] + B[j,k] * A[i,j]\n",
    "g= EGraph(:(reduceDim($+, $is, reduceDim($+, $ks, MapJoin($+, $c, MapJoin($*, $b, $a))))))\n",
    "analyze!(g, :TensorStatsAnalysis)\n",
    "params = SaturationParams(timeout=10, eclasslimit=4000)\n",
    "report = saturate!(g, basic_rewrites, params);\n",
    "\n",
    "# Results In:(Sum_k,i C[j,l]) + (Sum_k B[j,k]) * (Sum_i A[i,j])\n",
    "pprintln(extract!(g, simple_cardinality_cost_function))\n",
    "print(report)\n",
    "getdata(g[g.root], :TensorStatsAnalysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is = Set([\"i\"])\n",
    "js = Set([\"j\"])\n",
    "ks = Set([\"k\"])\n",
    "x_indices = Set([\"i\", \"j\"])\n",
    "x_dimSizes = Dict(\"i\" => 1000, \"j\"=>1000)\n",
    "x = InputTensor(TensorStats(x_indices, x_dimSizes, 100, 0.0), \"X\")\n",
    "u_indices = Set([\"i\", \"k\"])\n",
    "u_dimSizes = Dict(\"i\" => 1000, \"k\"=>10)\n",
    "u = InputTensor(TensorStats(u_indices, u_dimSizes, 10000, 0.0), \"U\")\n",
    "v_indices = Set([\"k\", \"j\"])\n",
    "v_dimSizes = Dict(\"k\" => 10, \"j\" => 1000)\n",
    "v = InputTensor(TensorStats(v_indices, v_dimSizes, 10000, 0.0), \"V\")\n",
    "\n",
    "# Sum_i Sum_k C[j,l] + B[j,k] * A[i,j]\n",
    "g= EGraph(:(reduceDim($+, $is, reduceDim($+, $js, mapScalar($^, MapJoin($+, $x, reduceDim($+, $ks, MapJoin($*, $u, $v))), $2)))))\n",
    "\n",
    "analyze!(g, :TensorStatsAnalysis)\n",
    "params = SaturationParams(timeout=100, eclasslimit=4000)\n",
    "report = saturate!(g, basic_rewrites, params);\n",
    "\n",
    "# Results In:(Sum_k,i C[j,l]) + (Sum_i B[j,k]) * (Sum_k A[i,j])\n",
    "pprintln(extract!(g, simple_cardinality_cost_function))\n",
    "print(report)\n",
    "getdata(g[g.root], :TensorStatsAnalysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "AssertionError: isempty(MERGES_BUF[])",
     "output_type": "error",
     "traceback": [
      "AssertionError: isempty(MERGES_BUF[])",
      "",
      "Stacktrace:",
      " [1] eqsat_apply!",
      "   @ ~/.julia/packages/Metatheory/6aio8/src/EGraphs/saturation.jl:216 [inlined]",
      " [2] macro expansion",
      "   @ ~/.julia/packages/TimerOutputs/RsWnF/src/TimerOutput.jl:237 [inlined]",
      " [3] eqsat_step!(g::EGraph, theory::Vector{AbstractRule}, curr_iter::Int64, scheduler::Metatheory.EGraphs.Schedulers.BackoffScheduler, params::SaturationParams, report::Metatheory.EGraphs.SaturationReport)",
      "   @ Metatheory.EGraphs ~/.julia/packages/Metatheory/6aio8/src/EGraphs/saturation.jl:272",
      " [4] saturate!(g::EGraph, theory::Vector{AbstractRule}, params::SaturationParams)",
      "   @ Metatheory.EGraphs ~/.julia/packages/Metatheory/6aio8/src/EGraphs/saturation.jl:302",
      " [5] top-level scope",
      "   @ In[11]:20",
      " [6] eval",
      "   @ ./boot.jl:368 [inlined]",
      " [7] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1428"
     ]
    }
   ],
   "source": [
    "is = Set([\"i\"])\n",
    "js = Set([\"j\"])\n",
    "ks = Set([\"k\"])\n",
    "tensors = []\n",
    "for i in 1:10\n",
    "    indices = Set([\"i_\" *  string(i), \"i_\" * string(i+1)])\n",
    "    dimSizes = Dict()\n",
    "    for index in indices\n",
    "        dimSizes[index] = 100\n",
    "    end\n",
    "    push!(tensors, InputTensor(\"A_\" * string(i), TensorStats(indices, dimSizes, 10000, 0.0)))\n",
    "end\n",
    "\n",
    "\n",
    "# Optimization w/cross products\n",
    "#g= EGraph(:(MapJoin($*, $(tensors[1]), MapJoin($*, $(tensors[2]), MapJoin($*, $(tensors[3]), MapJoin($*, $(tensors[4]), MapJoin($*, $(tensors[5]), MapJoin($*, $(tensors[6]), MapJoin($*, $(tensors[7]), MapJoin($*, $(tensors[8]), $(tensors[9])))))))))))\n",
    "g= EGraph(:(MapJoin($*, $(tensors[1]), MapJoin($*, $(tensors[2]), MapJoin($*, $(tensors[3]), MapJoin($*, $(tensors[4]), MapJoin($*, $(tensors[5]), MapJoin($*, $(tensors[6]), MapJoin($*, $(tensors[7]), $(tensors[8]))))))))))\n",
    "analyze!(g, :TensorStatsAnalysis)\n",
    "params = SaturationParams(timeout=10, eclasslimit=100000)\n",
    "report = saturate!(g, basic_rewrites, params);\n",
    "\n",
    "pprintln(extract!(g, simple_cardinality_cost_function))\n",
    "print(report)\n",
    "getdata(g[g.root], :TensorStatsAnalysis)\n",
    "\n",
    "\n",
    "\n",
    "# Optimization w/out cross-products\n",
    "#g= EGraph(:(MapJoin($*, $(tensors[1]), MapJoin($*, $(tensors[2]), MapJoin($*, $(tensors[3]), MapJoin($*, $(tensors[4]), MapJoin($*, $(tensors[5]), MapJoin($*, $(tensors[6]), MapJoin($*, $(tensors[7]), MapJoin($*, $(tensors[8]), $(tensors[9])))))))))))\n",
    "g= EGraph(:(MapJoin($*, $(tensors[1]), MapJoin($*, $(tensors[2]), MapJoin($*, $(tensors[3]), MapJoin($*, $(tensors[4]), MapJoin($*, $(tensors[5]), MapJoin($*, $(tensors[6]), MapJoin($*, $(tensors[7]), $(tensors[8]))))))))))\n",
    "analyze!(g, :TensorStatsAnalysis)\n",
    "params = SaturationParams(timeout=10, eclasslimit=100000)\n",
    "report = saturate!(g, basic_rewrites_2, params);\n",
    "\n",
    "pprintln(extract!(g, simple_cardinality_cost_function))\n",
    "print(report)\n",
    "getdata(g[g.root], :TensorStatsAnalysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63708"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.3",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
