{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uniform_fiber (generic function with 1 method)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Finch\n",
    "using SparseArrays\n",
    "using Metatheory\n",
    "using Metatheory.EGraphs\n",
    "using TermInterface\n",
    "using PrettyPrinting\n",
    "include(\"../Source/Spartan.jl\")\n",
    "include(\"../Source/UtilityFuncs.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expression: \n",
      "quote\n",
      "    ReduceDim(\n",
      "        +,\n",
      "        [\"i\", \"l\"],\n",
      "        MapJoin(\n",
      "            *,\n",
      "            InputTensor(B, TensorStats([\"j\", \"l\"], Dict(\"j\" => 1000, \"l\" => 10000), 100267.0, 0, Any[\"i\", \"j\", \"l\"])),\n",
      "            MapJoin(\n",
      "                *,\n",
      "                InputTensor(A, TensorStats([\"i\", \"j\"], Dict(\"j\" => 1000, \"i\" => 10000), 100255.0, 0, Any[\"i\", \"j\", \"l\"])),\n",
      "                InputTensor(C, TensorStats([\"j\", \"l\"], Dict(\"j\" => 1000, \"l\" => 10000), 99734.0, 0, Any[\"i\", \"j\", \"l\"])))))\n",
      "end\n",
      "Time to Execute: 5.515714181\n",
      "Optimized Expression: \n",
      "quote\n",
      "    ReduceDim(\n",
      "        +,\n",
      "        [\"l\"],\n",
      "        MapJoin(\n",
      "            *,\n",
      "            MapJoin(\n",
      "                *,\n",
      "                InputTensor(C, TensorStats([\"j\", \"l\"], Dict(\"j\" => 1000, \"l\" => 10000), 99734.0, 0, [\"i\", \"j\", \"l\"])),\n",
      "                InputTensor(B, TensorStats([\"j\", \"l\"], Dict(\"j\" => 1000, \"l\" => 10000), 100267.0, 0, [\"i\", \"j\", \"l\"]))),\n",
      "            ReduceDim(\n",
      "                +,\n",
      "                [\"i\"],\n",
      "                InputTensor(A, TensorStats([\"i\", \"j\"], Dict(\"j\" => 1000, \"i\" => 10000), 100255.0, 0, [\"i\", \"j\", \"l\"])))))\n",
      "end\n",
      "Time to Execute: 1.428242123\n",
      "Optimized Expression: \n",
      "quote\n",
      "    ReduceDim(\n",
      "        +,\n",
      "        [\"l\"],\n",
      "        MapJoin(\n",
      "            *,\n",
      "            MapJoin(\n",
      "                *,\n",
      "                Reorder(\n",
      "                    InputTensor(C, TensorStats([\"j\", \"l\"], Dict(\"j\" => 1000, \"l\" => 10000), 99734.0, 0, [\"l\", \"j\", \"i\"])),\n",
      "                    [\"l\", \"j\", \"i\"]),\n",
      "                Reorder(\n",
      "                    InputTensor(B, TensorStats([\"j\", \"l\"], Dict(\"j\" => 1000, \"l\" => 10000), 100267.0, 0, [\"l\", \"j\", \"i\"])),\n",
      "                    [\"l\", \"j\", \"i\"])),\n",
      "            ReduceDim(\n",
      "                +,\n",
      "                [\"i\"],\n",
      "                Reorder(\n",
      "                    InputTensor(A, TensorStats([\"i\", \"j\"], Dict(\"j\" => 1000, \"i\" => 10000), 100255.0, 0, [\"l\", \"j\", \"i\"])),\n",
      "                    [\"l\", \"j\", \"i\"]))))\n",
      "end\n",
      "Time to Execute: 3.719940724\n",
      "Optimized Expression: \n",
      "quote\n",
      "    ReduceDim(\n",
      "        +,\n",
      "        [\"l\"],\n",
      "        MapJoin(\n",
      "            *,\n",
      "            MapJoin(\n",
      "                *,\n",
      "                InputTensor(C, TensorStats([\"j\", \"l\"], Dict(\"j\" => 1000, \"l\" => 10000), 99734.0, 0, [\"j\", \"l\", \"i\"])),\n",
      "                InputTensor(B, TensorStats([\"j\", \"l\"], Dict(\"j\" => 1000, \"l\" => 10000), 100267.0, 0, [\"j\", \"l\", \"i\"]))),\n",
      "            ReduceDim(\n",
      "                +,\n",
      "                [\"i\"],\n",
      "                Reorder(\n",
      "                    InputTensor(A, TensorStats([\"i\", \"j\"], Dict(\"j\" => 1000, \"i\" => 10000), 100255.0, 0, [\"j\", \"l\", \"i\"])),\n",
      "                    [\"j\", \"l\", \"i\"]))))\n",
      "end\n",
      "Time to Execute: 0.653788874\n",
      "Optimized Expression: \n",
      "quote\n",
      "    ReduceDim(\n",
      "        +,\n",
      "        [\"l\"],\n",
      "        MapJoin(\n",
      "            *,\n",
      "            MapJoin(\n",
      "                *,\n",
      "                Reorder(\n",
      "                    InputTensor(C, TensorStats([\"j\", \"l\"], Dict(\"j\" => 1000, \"l\" => 10000), 99734.0, 0, [\"i\", \"l\", \"j\"])),\n",
      "                    [\"i\", \"l\", \"j\"]),\n",
      "                Reorder(\n",
      "                    InputTensor(B, TensorStats([\"j\", \"l\"], Dict(\"j\" => 1000, \"l\" => 10000), 100267.0, 0, [\"i\", \"l\", \"j\"])),\n",
      "                    [\"i\", \"l\", \"j\"])),\n",
      "            ReduceDim(\n",
      "                +,\n",
      "                [\"i\"],\n",
      "                InputTensor(A, TensorStats([\"i\", \"j\"], Dict(\"j\" => 1000, \"i\" => 10000), 100255.0, 0, [\"i\", \"l\", \"j\"])))))\n",
      "end\n",
      "Time to Execute: 0.757359284\n",
      "Is Correct?: true\n"
     ]
    }
   ],
   "source": [
    "is = [\"i\", \"l\"]\n",
    "A = InputTensor(\"A\", [\"i\", \"j\"], uniform_fiber([10000, 1000], .01))\n",
    "B = InputTensor(\"B\", [\"j\", \"l\"], uniform_fiber([1000, 10000], .01))\n",
    "C = InputTensor(\"C\", [\"j\", \"l\"], uniform_fiber([1000, 10000], .01))\n",
    "output_order = [\"j\", \"i\"]\n",
    "\n",
    "verbose = 1\n",
    "# Sum_i Sum_l B[j,l]*A[i,j]*A[i,j]\n",
    "output_tensor_1 = spartan(:(Reorder(ReduceDim($+, $is,  MapJoin($*, $B, MapJoin($*, $A, $C))), $output_order)), verbose=verbose, optimize=false)\n",
    "#println(output_tensor)\n",
    "\n",
    "global_index_order = [\"i\", \"j\", \"l\"]\n",
    "# (Sum_l B[j,l])*(Sum_i A[i,j] * A[i,j])\n",
    "output_tensor_2 = spartan(:(Reorder(ReduceDim($+, $is, MapJoin($*, $B, MapJoin($*, $A, $C))), $output_order)), verbose=verbose,\n",
    "                             global_index_order = global_index_order, optimize=true)\n",
    "\n",
    "global_index_order = [\"l\", \"j\", \"i\"]\n",
    "output_tensor_3 = spartan(:(Reorder(ReduceDim($+, $is, MapJoin($*, $B, MapJoin($*, $A, $C))), $output_order)), verbose=verbose,\n",
    "                             global_index_order = global_index_order, optimize=true)\n",
    "\n",
    "\n",
    "\n",
    "global_index_order = [\"j\", \"l\", \"i\"]\n",
    "output_tensor_4 = spartan(:(Reorder(ReduceDim($+, $is, MapJoin($*, $B, MapJoin($*, $A, $C))), $output_order)), verbose=verbose,\n",
    "                             global_index_order = global_index_order, optimize=true)\n",
    "\n",
    "\n",
    "global_index_order = [\"i\", \"l\", \"j\"]\n",
    "output_tensor_5 = spartan(:(Reorder(ReduceDim($+, $is, MapJoin($*, $B, MapJoin($*, $A, $C))), $output_order)), verbose=verbose,\n",
    "                            global_index_order = global_index_order, optimize=true)\n",
    "\n",
    "println(\"Is Correct?: \", output_tensor_1 == output_tensor_2 && output_tensor_2 == output_tensor_3 && \n",
    "                                output_tensor_3 == output_tensor_4 && output_tensor_4 == output_tensor_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is = [\"i\", \"j\"]\n",
    "B = InputTensor(\"B\", [\"i\", \"k\", \"l\"], uniform_fiber([1000, 1000, 1000], .01))\n",
    "D = InputTensor(\"D\", [\"l\", \"j\"], uniform_fiber([1000, 100], 1.0))\n",
    "C = InputTensor(\"C\", [\"k\", \"j\"], uniform_fiber([1000, 100], 1.0))\n",
    "\n",
    "verbose = 1\n",
    "MTTKRP = :(ReduceDim($+, $is, MapJoin($*, $B, MapJoin($C, $D))))\n",
    "output_tensor_1 = spartan(MTTKRP, optimize=false)\n",
    "output_tensor_2 = spartan(MTTKRP, optimize=true)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expression: \n",
      "quote\n",
      "    ReduceDim(\n",
      "        +,\n",
      "        [\"i\", \"j\"],\n",
      "        MapJoin(\n",
      "            ^,\n",
      "            MapJoin(\n",
      "                +,\n",
      "                InputTensor(X, TensorStats([\"i\", \"j\"], Dict(\"j\" => 1000, \"i\" => 1000), 10186.0, 0, Any[\"i\", \"j\"])),\n",
      "                MapJoin(\n",
      "                    *,\n",
      "                    InputTensor(u, TensorStats([\"i\"], Dict(\"i\" => 1000), 1000.0, 0, Any[\"i\", \"j\"])),\n",
      "                    InputTensor(v, TensorStats([\"j\"], Dict(\"j\" => 1000), 1000.0, 0, Any[\"i\", \"j\"])))),\n",
      "            2))\n",
      "end\n",
      "Time to Execute: 1.019511778\n",
      "Optimized Expression: \n",
      "quote\n",
      "    MapJoin(\n",
      "        +,\n",
      "        MapJoin(\n",
      "            +,\n",
      "            ReduceDim(\n",
      "                +,\n",
      "                [\"j\"],\n",
      "                MapJoin(\n",
      "                    *,\n",
      "                    InputTensor(v, TensorStats([\"j\"], Dict(\"j\" => 1000), 1000.0, 0, Any[\"i\", \"j\"])),\n",
      "                    ReduceDim(\n",
      "                        +,\n",
      "                        [\"i\"],\n",
      "                        MapJoin(\n",
      "                            *,\n",
      "                            InputTensor(X, TensorStats([\"i\", \"j\"], Dict(\"j\" => 1000, \"i\" => 1000), 10186.0, 0, Any[\"i\", \"j\"])),\n",
      "                            InputTensor(u, TensorStats([\"i\"], Dict(\"i\" => 1000), 1000.0, 0, Any[\"i\", \"j\"])))))),\n",
      "            MapJoin(\n",
      "                +,\n",
      "                MapJoin(\n",
      "                    *,\n",
      "                    ReduceDim(\n",
      "                        +,\n",
      "                        [\"i\"],\n",
      "                        MapJoin(\n",
      "                            ^,\n",
      "                            InputTensor(u, TensorStats([\"i\"], Dict(\"i\" => 1000), 1000.0, 0, Any[\"i\", \"j\"])),\n",
      "                            2)),\n",
      "                    ReduceDim(\n",
      "                        +,\n",
      "                        [\"j\"],\n",
      "                        MapJoin(\n",
      "                            ^,\n",
      "                            InputTensor(v, TensorStats([\"j\"], Dict(\"j\" => 1000), 1000.0, 0, Any[\"i\", \"j\"])),\n",
      "                            2))),\n",
      "                ReduceDim(\n",
      "                    +,\n",
      "                    [\"j\"],\n",
      "                    MapJoin(\n",
      "                        *,\n",
      "                        InputTensor(v, TensorStats([\"j\"], Dict(\"j\" => 1000), 1000.0, 0, Any[\"i\", \"j\"])),\n",
      "                        ReduceDim(\n",
      "                            +,\n",
      "                            [\"i\"],\n",
      "                            MapJoin(\n",
      "                                *,\n",
      "                                InputTensor(X, TensorStats([\"i\", \"j\"], Dict(\"j\" => 1000, \"i\" => 1000), 10186.0, 0, Any[\"i\", \"j\"])),\n",
      "                                InputTensor(u, TensorStats([\"i\"], Dict(\"i\" => 1000), 1000.0, 0, Any[\"i\", \"j\"])))))))),\n",
      "        ReduceDim(\n",
      "            +,\n",
      "            [\"j\", \"i\"],\n",
      "            MapJoin(\n",
      "                ^,\n",
      "                InputTensor(X, TensorStats([\"i\", \"j\"], Dict(\"j\" => 1000, \"i\" => 1000), 10186.0, 0, Any[\"i\", \"j\"])),\n",
      "                2)))\n",
      "end\n",
      "Time to Execute: 0.146112238\n",
      "Is Correct?: true\n"
     ]
    }
   ],
   "source": [
    "is = [\"i\", \"j\"]\n",
    "X = InputTensor(\"X\", [\"i\", \"j\"], uniform_fiber([1000, 1000], .01))\n",
    "u = InputTensor(\"u\", [\"i\"], uniform_fiber([1000], 1.0))\n",
    "v = InputTensor(\"v\", [\"j\"], uniform_fiber([1000], 1.0))\n",
    "\n",
    "verbose = 1\n",
    "# Sum_i Sum_j (X[i,j]+u[i]*v[j])\n",
    "output_tensor_1 = spartan(:(ReduceDim($+, $is, MapJoin($^, MapJoin($+, $X, MapJoin($*, $u, $v)), 2))), verbose=verbose, optimize=false)\n",
    "\n",
    "# (Sum_i u[i]^2)*(Sum_j v[j]^2) + (Sum_i u[i] * (Sum_j X[i,j] * V[j])) + (Sum_i u[i] * (Sum_j X[i,j] * V[j])) + (Sum_[i,j] X[i,j]^2)\n",
    "output_tensor_2 = spartan(:(ReduceDim($+, $is, MapJoin($^, MapJoin($+, $X, MapJoin($*, $u, $v)), 2))), verbose=verbose, optimize=true)\n",
    "\n",
    "println(\"Is Correct?: \", output_tensor_1 == output_tensor_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expression: \n",
      "quote\n",
      "    ReduceDim(\n",
      "        +,\n",
      "        [\"i\", \"j\", \"k\"],\n",
      "        MapJoin(\n",
      "            *,\n",
      "            InputTensor(E, TensorStats([\"i\", \"j\"], Dict(\"j\" => 1000, \"i\" => 1000), 19862.0, 0, Any[\"i\", \"j\", \"k\", \"l\"])),\n",
      "            MapJoin(\n",
      "                *,\n",
      "                InputTensor(E, TensorStats([\"j\", \"k\"], Dict(\"j\" => 1000, \"k\" => 1000), 19862.0, 0, Any[\"i\", \"j\", \"k\", \"l\"])),\n",
      "                MapJoin(\n",
      "                    *,\n",
      "                    InputTensor(E, TensorStats([\"k\", \"l\"], Dict(\"k\" => 1000, \"l\" => 1000), 19862.0, 0, Any[\"i\", \"j\", \"k\", \"l\"])),\n",
      "                    Reorder(\n",
      "                        InputTensor(E, TensorStats([\"l\", \"i\"], Dict(\"l\" => 1000, \"i\" => 1000), 19862.0, 0, Any[\"i\", \"j\", \"k\", \"l\"])),\n",
      "                        [\"i\", \"j\", \"k\", \"l\"])))))\n",
      "end\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "5\n",
      "Kernel: ReorderExpr([\"i\", \"j\", \"k\", \"l\"], InputExpr(\"A\", [\"l\", \"i\"], AccessProtocol[t_walk, t_walk], TensorStats([\"l\", \"i\"], Dict(\"l\" => 1000, \"i\" => 1000), 19862.0, 0, Any[\"i\", \"j\", \"k\", \"l\"])))\n",
      "Output Order: [\"i\", \"l\"]\n",
      "Loop Order: [\"l\", \"i\"]\n",
      "Expected Output Tensor Size: 19862.0\n",
      "Output Tensor Size: 19862\n",
      "4\n",
      "Kernel: OperatorExpr(*, InputExpr[InputExpr(\"A\", [\"k\", \"l\"], AccessProtocol[t_walk, t_walk], TensorStats([\"k\", \"l\"], Dict(\"k\" => 1000, \"l\" => 1000), 19862.0, 0, Any[\"i\", \"j\", \"k\", \"l\"])), InputExpr(\"B\", [\"i\", \"l\"], AccessProtocol[t_walk, t_walk], TensorStats([\"i\", \"l\"], Dict(\"l\" => 1000, \"i\" => 1000), 19862.0, 0, [\"i\", \"j\", \"k\", \"l\"]))])\n",
      "Output Order: [\"i\", \"k\", \"l\"]\n",
      "Loop Order: [\"l\", \"k\", \"i\"]\n",
      "Expected Output Tensor Size: 394499.04400000005\n",
      "Output Tensor Size: 394581\n",
      "3\n",
      "Kernel: OperatorExpr(*, InputExpr[InputExpr(\"A\", [\"j\", \"k\"], AccessProtocol[t_walk, t_walk], TensorStats([\"j\", \"k\"], Dict(\"j\" => 1000, \"k\" => 1000), 19862.0, 0, Any[\"i\", \"j\", \"k\", \"l\"])), InputExpr(\"B\", [\"i\", \"k\", \"l\"], AccessProtocol[t_walk, t_walk, t_walk], TensorStats([\"i\", \"k\", \"l\"], Dict(\"k\" => 1000, \"l\" => 1000, \"i\" => 1000), 394499.04400000005, 0, Any[\"i\", \"j\", \"k\", \"l\"]))])\n",
      "Output Order: [\"i\", \"j\", \"k\", \"l\"]\n",
      "Loop Order: [\"l\", \"k\", \"j\", \"i\"]\n",
      "Expected Output Tensor Size: 7.835540011928001e6\n",
      "Output Tensor Size: 7836813\n",
      "2\n",
      "Kernel: OperatorExpr(*, InputExpr[InputExpr(\"A\", [\"i\", \"j\"], AccessProtocol[t_walk, t_walk], TensorStats([\"i\", \"j\"], Dict(\"j\" => 1000, \"i\" => 1000), 19862.0, 0, Any[\"i\", \"j\", \"k\", \"l\"])), InputExpr(\"B\", [\"i\", \"j\", \"k\", \"l\"], AccessProtocol[t_walk, t_walk, t_walk, t_walk], TensorStats([\"i\", \"j\", \"k\", \"l\"], Dict(\"j\" => 1000, \"k\" => 1000, \"l\" => 1000, \"i\" => 1000), 7.835540011928001e6, 0, Any[\"i\", \"j\", \"k\", \"l\"]))])\n",
      "Output Order: [\"i\", \"j\", \"k\", \"l\"]\n",
      "Loop Order: [\"l\", \"k\", \"j\", \"i\"]\n",
      "Expected Output Tensor Size: 155629.49571691398\n",
      "Output Tensor Size: 156624\n",
      "1\n",
      "Kernel: AggregateExpr(+, [\"i\", \"j\", \"k\"], InputExpr(\"A\", [\"i\", \"j\", \"k\", \"l\"], AccessProtocol[t_walk, t_walk, t_walk, t_walk], TensorStats([\"i\", \"j\", \"k\", \"l\"], Dict(\"j\" => 1000, \"k\" => 1000, \"l\" => 1000, \"i\" => 1000), 155629.49571691398, 0, Any[\"i\", \"j\", \"k\", \"l\"])))\n",
      "Output Order: [\"l\"]\n",
      "Loop Order: [\"l\", \"k\", \"j\", \"i\"]\n",
      "Expected Output Tensor Size: 1000.0\n",
      "Output Tensor Size: 1000\n",
      "Time to Execute: 7.020406279\n",
      "SaturationReport\n",
      "=================\n",
      "\tStop Reason: saturated\n",
      "\tIterations: 8\n",
      "\tEGraph Size: 52 eclasses, 249 nodes\n",
      "\u001b[0m\u001b[1m ────────────────────────────────────────────────────────────────────\u001b[22m\n",
      "\u001b[0m\u001b[1m                   \u001b[22m         Time                    Allocations      \n",
      "                   ───────────────────────   ────────────────────────\n",
      " Tot / % measured:     27.6ms /  99.6%           13.8MiB / 100.0%    \n",
      "\n",
      " Section   ncalls     time    %tot     avg     alloc    %tot      avg\n",
      " ────────────────────────────────────────────────────────────────────\n",
      " Apply          8   12.8ms   46.6%  1.60ms   4.87MiB   35.3%   623KiB\n",
      " Search         8   9.07ms   32.9%  1.13ms   6.78MiB   49.2%   868KiB\n",
      "   11           8   1.36ms    4.9%   170μs   1.32MiB    9.6%   169KiB\n",
      "   6            8   1.12ms    4.1%   140μs    762KiB    5.4%  95.2KiB\n",
      "   5            8    811μs    2.9%   101μs    711KiB    5.0%  88.9KiB\n",
      "   9            8    773μs    2.8%  96.7μs    598KiB    4.2%  74.8KiB\n",
      "   3            8    701μs    2.5%  87.7μs    559KiB    4.0%  69.9KiB\n",
      "   4            8    682μs    2.5%  85.2μs    333KiB    2.4%  41.6KiB\n",
      "   8            8    674μs    2.4%  84.3μs    615KiB    4.4%  76.8KiB\n",
      "   14           8    667μs    2.4%  83.4μs    488KiB    3.5%  61.0KiB\n",
      "   12           8    564μs    2.0%  70.5μs    433KiB    3.1%  54.1KiB\n",
      "   1            8    493μs    1.8%  61.6μs    272KiB    1.9%  34.0KiB\n",
      "   10           8    454μs    1.6%  56.7μs    372KiB    2.6%  46.5KiB\n",
      "   7            8    289μs    1.0%  36.1μs    159KiB    1.1%  19.8KiB\n",
      "   13           8    218μs    0.8%  27.2μs    131KiB    0.9%  16.4KiB\n",
      "   2            8    213μs    0.8%  26.7μs    142KiB    1.0%  17.8KiB\n",
      " Rebuild        8   5.63ms   20.4%   704μs   2.13MiB   15.4%   273KiB\n",
      "\u001b[0m\u001b[1m ────────────────────────────────────────────────────────────────────\u001b[22m\n",
      "\n",
      "Optimized Expression: \n",
      "quote\n",
      "    ReduceDim(\n",
      "        +,\n",
      "        [\"i\", \"j\", \"k\"],\n",
      "        MapJoin(\n",
      "            *,\n",
      "            MapJoin(\n",
      "                *,\n",
      "                InputTensor(E, TensorStats([\"j\", \"k\"], Dict(\"j\" => 1000, \"k\" => 1000), 19862.0, 0, Any[\"i\", \"j\", \"k\", \"l\"])),\n",
      "                InputTensor(E, TensorStats([\"i\", \"j\"], Dict(\"j\" => 1000, \"i\" => 1000), 19862.0, 0, Any[\"i\", \"j\", \"k\", \"l\"]))),\n",
      "            MapJoin(\n",
      "                *,\n",
      "                Reorder(\n",
      "                    InputTensor(E, TensorStats([\"l\", \"i\"], Dict(\"l\" => 1000, \"i\" => 1000), 19862.0, 0, Any[\"i\", \"j\", \"k\", \"l\"])),\n",
      "                    [\"i\", \"j\", \"k\", \"l\"]),\n",
      "                InputTensor(E, TensorStats([\"k\", \"l\"], Dict(\"k\" => 1000, \"l\" => 1000), 19862.0, 0, Any[\"i\", \"j\", \"k\", \"l\"])))))\n",
      "end\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "Kernel: ReorderExpr([\"i\", \"j\", \"k\", \"l\"], InputExpr(\"A\", [\"l\", \"i\"], AccessProtocol[t_walk, t_walk], TensorStats([\"l\", \"i\"], Dict(\"l\" => 1000, \"i\" => 1000), 19862.0, 0, Any[\"i\", \"j\", \"k\", \"l\"])))\n",
      "Output Order: [\"i\", \"l\"]\n",
      "Loop Order: [\"l\", \"i\"]\n",
      "Expected Output Tensor Size: 19862.0\n",
      "Output Tensor Size: 19862\n",
      "3\n",
      "Kernel: OperatorExpr(*, InputExpr[InputExpr(\"A\", [\"i\", \"l\"], AccessProtocol[t_walk, t_walk], TensorStats([\"i\", \"l\"], Dict(\"l\" => 1000, \"i\" => 1000), 19862.0, 0, [\"i\", \"j\", \"k\", \"l\"])), InputExpr(\"B\", [\"k\", \"l\"], AccessProtocol[t_walk, t_walk], TensorStats([\"k\", \"l\"], Dict(\"k\" => 1000, \"l\" => 1000), 19862.0, 0, Any[\"i\", \"j\", \"k\", \"l\"]))])\n",
      "Output Order: [\"i\", \"k\", \"l\"]\n",
      "Loop Order: [\"l\", \"k\", \"i\"]\n",
      "Expected Output Tensor Size: 394499.04400000005\n",
      "Output Tensor Size: 394581\n",
      "3\n",
      "3\n",
      "Kernel: OperatorExpr(*, InputExpr[InputExpr(\"A\", [\"j\", \"k\"], AccessProtocol[t_walk, t_walk], TensorStats([\"j\", \"k\"], Dict(\"j\" => 1000, \"k\" => 1000), 19862.0, 0, Any[\"i\", \"j\", \"k\", \"l\"])), InputExpr(\"B\", [\"i\", \"j\"], AccessProtocol[t_walk, t_walk], TensorStats([\"i\", \"j\"], Dict(\"j\" => 1000, \"i\" => 1000), 19862.0, 0, Any[\"i\", \"j\", \"k\", \"l\"]))])\n",
      "Output Order: [\"i\", \"j\", \"k\"]\n",
      "Loop Order: [\"k\", \"j\", \"i\"]\n",
      "Expected Output Tensor Size: 394499.04400000005\n",
      "Output Tensor Size: 394581\n",
      "2\n",
      "Kernel: OperatorExpr(*, InputExpr[InputExpr(\"A\", [\"i\", \"j\", \"k\"], AccessProtocol[t_walk, t_walk, t_walk], TensorStats([\"i\", \"j\", \"k\"], Dict(\"j\" => 1000, \"k\" => 1000, \"i\" => 1000), 394499.04400000005, 0, Any[\"i\", \"j\", \"k\", \"l\"])), InputExpr(\"B\", [\"i\", \"k\", \"l\"], AccessProtocol[t_walk, t_walk, t_walk], TensorStats([\"i\", \"k\", \"l\"], Dict(\"k\" => 1000, \"l\" => 1000, \"i\" => 1000), 394499.04400000005, 0, [\"i\", \"j\", \"k\", \"l\"]))])\n",
      "Output Order: [\"i\", \"j\", \"k\", \"l\"]\n",
      "Loop Order: [\"l\", \"k\", \"j\", \"i\"]\n",
      "Expected Output Tensor Size: 155629.49571691398\n",
      "Output Tensor Size: 156624\n",
      "1\n",
      "Kernel: AggregateExpr(+, [\"i\", \"j\", \"k\"], InputExpr(\"A\", [\"i\", \"j\", \"k\", \"l\"], AccessProtocol[t_walk, t_walk, t_walk, t_walk], TensorStats([\"i\", \"j\", \"k\", \"l\"], Dict(\"j\" => 1000, \"k\" => 1000, \"l\" => 1000, \"i\" => 1000), 155629.49571691398, 0, Any[\"i\", \"j\", \"k\", \"l\"])))\n",
      "Output Order: [\"l\"]\n",
      "Loop Order: [\"l\", \"k\", \"j\", \"i\"]\n",
      "Expected Output Tensor Size: 1000.0\n",
      "Output Tensor Size: 1000\n",
      "Time to Execute: 2.405293543\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SparseHash (0) [1:1000]\n",
       "├─[1]: 222\n",
       "├─[2]: 85\n",
       "│ ⋮\n",
       "├─[999]: 150\n",
       "├─[1000]: 119"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is = [\"i\", \"j\", \"k\"]\n",
    "E_fiber = uniform_fiber([1000, 1000], .02)\n",
    "E_1 = InputTensor(\"E\", [\"i\", \"j\"], E_fiber)\n",
    "E_2 = InputTensor(\"E\", [\"j\", \"k\"], E_fiber)\n",
    "E_3 = InputTensor(\"E\", [\"k\", \"l\"], E_fiber)\n",
    "E_4 = InputTensor(\"E\", [\"l\", \"i\"], E_fiber)\n",
    "\n",
    "verbose = 3\n",
    "query = :(ReduceDim($+, $is, MapJoin($*, $E_1, MapJoin($*, $E_2, MapJoin($*, $E_3, $E_4)))))\n",
    "output_1 = spartan(query, verbose=verbose, optimize = false)\n",
    "output_2 = spartan(query, verbose=verbose, optimize = true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Expression: \n",
      "quote\n",
      "    MapJoin(\n",
      "        +,\n",
      "        ReduceDim(\n",
      "            +,\n",
      "            [\"j\"],\n",
      "            MapJoin(\n",
      "                min,\n",
      "                ReduceDim(\n",
      "                    +,\n",
      "                    [\"lat2\", \"long2\"],\n",
      "                    MapJoin(\n",
      "                        *,\n",
      "                        MapJoin(\n",
      "                            *,\n",
      "                            MapJoin(\n",
      "                                *,\n",
      "                                InputTensor(neighbor_node_power, TensorStats([\"j\"], Dict(\"j\" => 1000), 1000.0, 0, Any[\"i\", \"j\", \"lat\", \"lat2\", \"long\", \"long2\"])),\n",
      "                                InputTensor(neighbor_node_location, TensorStats([\"j\", \"lat2\", \"long2\"], Dict(\"long2\" => 100, \"j\" => 1000, \"lat2\" => 100), 971.0, 0, Any[\"i\", \"j\", \"lat\", \"lat2\", \"long\", \"long2\"]))),\n",
      "                            InputTensor(neighbor_weather_events, TensorStats([\"lat2\", \"long2\"], Dict(\"long2\" => 100, \"lat2\" => 100), 98.0, 1, Any[\"i\", \"j\", \"lat\", \"lat2\", \"long\", \"long2\"]))),\n",
      "                        InputTensor(neighbor_node_outage_percents, TensorStats([\"j\"], Dict(\"j\" => 1000), 88.0, 1, Any[\"i\", \"j\", \"lat\", \"lat2\", \"long\", \"long2\"])))),\n",
      "                InputTensor(transmission_capacity, TensorStats([\"i\", \"j\"], Dict(\"j\" => 1000, \"i\" => 1000), 5076.0, 0, Any[\"i\", \"j\", \"lat\", \"lat2\", \"long\", \"long2\"])))),\n",
      "        MapJoin(\n",
      "            *,\n",
      "            InputTensor(node_outage_percents, TensorStats([\"i\"], Dict(\"i\" => 1000), 88.0, 1, Any[\"i\", \"j\", \"lat\", \"lat2\", \"long\", \"long2\"])),\n",
      "            MapJoin(\n",
      "                *,\n",
      "                InputTensor(node_power, TensorStats([\"i\"], Dict(\"i\" => 1000), 1000.0, 0, Any[\"i\", \"j\", \"lat\", \"lat2\", \"long\", \"long2\"])),\n",
      "                ReduceDim(\n",
      "                    +,\n",
      "                    [\"lat\", \"long\"],\n",
      "                    MapJoin(\n",
      "                        *,\n",
      "                        InputTensor(weather_events, TensorStats([\"lat\", \"long\"], Dict(\"lat\" => 100, \"long\" => 100), 98.0, 1, Any[\"i\", \"j\", \"lat\", \"lat2\", \"long\", \"long2\"])),\n",
      "                        InputTensor(node_location, TensorStats([\"i\", \"lat\", \"long\"], Dict(\"lat\" => 100, \"long\" => 100, \"i\" => 1000), 971.0, 0, Any[\"i\", \"j\", \"lat\", \"lat2\", \"long\", \"long2\"])))))))\n",
      "end\n",
      "Time to Execute: 0.003468654\n",
      "Expression: \n",
      "quote\n",
      "    MapJoin(\n",
      "        +,\n",
      "        ReduceDim(\n",
      "            +,\n",
      "            [\"lat\", \"long\"],\n",
      "            MapJoin(\n",
      "                *,\n",
      "                InputTensor(node_location, TensorStats([\"i\", \"lat\", \"long\"], Dict(\"lat\" => 100, \"long\" => 100, \"i\" => 1000), 971.0, 0, Any[\"i\", \"j\", \"lat\", \"lat2\", \"long\", \"long2\"])),\n",
      "                MapJoin(\n",
      "                    *,\n",
      "                    InputTensor(weather_events, TensorStats([\"lat\", \"long\"], Dict(\"lat\" => 100, \"long\" => 100), 98.0, 1, Any[\"i\", \"j\", \"lat\", \"lat2\", \"long\", \"long2\"])),\n",
      "                    MapJoin(\n",
      "                        *,\n",
      "                        InputTensor(node_outage_percents, TensorStats([\"i\"], Dict(\"i\" => 1000), 88.0, 1, Any[\"i\", \"j\", \"lat\", \"lat2\", \"long\", \"long2\"])),\n",
      "                        InputTensor(node_power, TensorStats([\"i\"], Dict(\"i\" => 1000), 1000.0, 0, Any[\"i\", \"j\", \"lat\", \"lat2\", \"long\", \"long2\"])))))),\n",
      "        ReduceDim(\n",
      "            +,\n",
      "            [\"j\"],\n",
      "            MapJoin(\n",
      "                min,\n",
      "                ReduceDim(\n",
      "                    +,\n",
      "                    [\"lat2\", \"long2\"],\n",
      "                    MapJoin(\n",
      "                        *,\n",
      "                        InputTensor(neighbor_weather_events, TensorStats([\"lat2\", \"long2\"], Dict(\"long2\" => 100, \"lat2\" => 100), 98.0, 1, Any[\"i\", \"j\", \"lat\", \"lat2\", \"long\", \"long2\"])),\n",
      "                        MapJoin(\n",
      "                            *,\n",
      "                            InputTensor(neighbor_node_outage_percents, TensorStats([\"j\"], Dict(\"j\" => 1000), 88.0, 1, Any[\"i\", \"j\", \"lat\", \"lat2\", \"long\", \"long2\"])),\n",
      "                            MapJoin(\n",
      "                                *,\n",
      "                                InputTensor(neighbor_node_location, TensorStats([\"j\", \"lat2\", \"long2\"], Dict(\"long2\" => 100, \"j\" => 1000, \"lat2\" => 100), 971.0, 0, Any[\"i\", \"j\", \"lat\", \"lat2\", \"long\", \"long2\"])),\n",
      "                                InputTensor(neighbor_node_power, TensorStats([\"j\"], Dict(\"j\" => 1000), 1000.0, 0, Any[\"i\", \"j\", \"lat\", \"lat2\", \"long\", \"long2\"])))))),\n",
      "                InputTensor(transmission_capacity, TensorStats([\"i\", \"j\"], Dict(\"j\" => 1000, \"i\" => 1000), 5076.0, 0, Any[\"i\", \"j\", \"lat\", \"lat2\", \"long\", \"long2\"])))))\n",
      "end\n",
      "Time to Execute: 3.097466569\n",
      "Is Equivalent: true\n"
     ]
    }
   ],
   "source": [
    "# Suppose you have a network of power nodes and lines. Further, you need to take weather events/outages into account.\n",
    "# The following query provides the total available power at each node.\n",
    "num_nodes = 1000\n",
    "height = 100\n",
    "width = 100\n",
    "\n",
    "# Because we're dealing with positive numbers, the following is true.\n",
    "Finch.isassociative(::Finch.DefaultAlgebra, ::typeof(min)) = true\n",
    "Finch.iscommutative(::Finch.DefaultAlgebra, ::typeof(min)) = true\n",
    "Finch.isannihilator(::Finch.DefaultAlgebra, ::typeof(min), x) = x == 0\n",
    "\n",
    "transmission_capacity = InputTensor(\"transmission_capacity\", [\"i\", \"j\"], uniform_fiber([num_nodes, num_nodes], 5.0/num_nodes))\n",
    "\n",
    "node_location_data =  uniform_fiber([num_nodes, height, width], 1.0/height/width)\n",
    "node_location = InputTensor(\"node_location\", [\"i\", \"lat\", \"long\"], node_location_data)\n",
    "neighbor_node_location = InputTensor(\"neighbor_node_location\", [\"j\", \"lat2\", \"long2\"], node_location_data)\n",
    "\n",
    "weather_events_data = uniform_fiber([height, width], .01, default_value = 1, non_default_value = 0)\n",
    "weather_events = InputTensor(\"weather_events\", [\"lat\", \"long\"], weather_events_data)\n",
    "neighbor_weather_events = InputTensor(\"neighbor_weather_events\", [\"lat2\", \"long2\"], weather_events_data)\n",
    "\n",
    "outages_data = uniform_fiber([num_nodes], .1, default_value = 1, non_default_value = 0)\n",
    "node_outage_percents = InputTensor(\"node_outage_percents\", [\"i\"], outages_data)\n",
    "neighbor_node_outage_percents = InputTensor(\"neighbor_node_outage_percents\", [\"j\"], outages_data)\n",
    "\n",
    "node_power_data = uniform_fiber([num_nodes], 1.0)\n",
    "node_power = InputTensor(\"node_power\", [\"i\"], node_power_data)\n",
    "neighbor_node_power = InputTensor(\"neighbor_node_power\", [\"j\"], node_power_data)\n",
    "\n",
    "available_power_query = :(MapJoin($+, ReduceDim($+, ($[\"lat\", \"long\"]), MapJoin($*, $node_location, MapJoin($*, $weather_events, \n",
    "                                                                           MapJoin($*, $node_outage_percents, $node_power)))),\n",
    "                                      ReduceDim($+, ($[\"j\"]),\n",
    "                                            MapJoin($min, ReduceDim($+, $[\"lat2\", \"long2\"], MapJoin($*, $neighbor_weather_events, \n",
    "                                                    MapJoin($*, $neighbor_node_outage_percents, MapJoin($*, $neighbor_node_location, $neighbor_node_power)))), $transmission_capacity))))\n",
    "\n",
    "verbose = 1\n",
    "total_neighbor_power_1 = spartan(available_power_query, verbose=verbose, optimize=true)\n",
    "\n",
    "total_neighbor_power_2 = spartan(available_power_query, verbose=verbose, optimize=false)\n",
    "\n",
    "println(\"Is Equivalent: \", total_neighbor_power_1 == total_neighbor_power_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1013"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countstored(node_location_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseCOO (0.0) [1:100,1:100]\n",
       "├─├─[8, 1]: 0.5874481201442663\n",
       "├─├─[21, 1]: 0.8644518849715451\n",
       "│ ⋮\n",
       "├─├─[50, 100]: 0.3424241380122627\n",
       "├─├─[82, 100]: 0.9176587679719371"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Random\n",
    "I = Finch.fsprand_helper(Random.default_rng(), (100, 100), .01)\n",
    "V = [rand() for _ in 1:length(I[1])]\n",
    "fsparse(I,V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseList (2) [:,1:100]\n",
       "├─[:,1]: SparseList (2) [1:100]\n",
       "│ ├─[89]: 1\n",
       "├─[:,2]: SparseList (2) [1:100]\n",
       "│ ├─[39]: 1\n",
       "│ ├─[62]: 1\n",
       "│ ├─[78]: 1\n",
       "│ ⋮\n",
       "├─[:,98]: SparseList (2) [1:100]\n",
       "│ ├─[24]: 1\n",
       "├─[:,99]: SparseList (2) [1:100]\n",
       "│ ├─[52]: 1\n",
       "│ ├─[81]: 1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniform_fiber([100, 100], .01, non_default_value = 1, default_value = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseList (0) [:,:,1:100]\n",
       "├─[:,:,1]: SparseList (0) [:,1:100]\n",
       "│ ├─[:,5]: SparseList (0) [1:1000]\n",
       "│ │ ├─[328]: 1\n",
       "│ ├─[:,16]: SparseList (0) [1:1000]\n",
       "│ │ ├─[859]: 1\n",
       "│ │ ⋮\n",
       "│ ├─[:,93]: SparseList (0) [1:1000]\n",
       "│ │ ├─[343]: 1\n",
       "│ │ ├─[508]: 1\n",
       "│ ├─[:,99]: SparseList (0) [1:1000]\n",
       "│ │ ├─[338]: 1\n",
       "├─[:,:,2]: SparseList (0) [:,1:100]\n",
       "│ ├─[:,1]: SparseList (0) [1:1000]\n",
       "│ │ ├─[609]: 1\n",
       "│ ├─[:,3]: SparseList (0) [1:1000]\n",
       "│ │ ├─[560]: 1\n",
       "│ │ ⋮\n",
       "│ ├─[:,91]: SparseList (0) [1:1000]\n",
       "│ │ ├─[582]: 1\n",
       "│ ├─[:,92]: SparseList (0) [1:1000]\n",
       "│ │ ├─[129]: 1\n",
       "│ ⋮\n",
       "├─[:,:,99]: SparseList (0) [:,1:100]\n",
       "│ ├─[:,16]: SparseList (0) [1:1000]\n",
       "│ │ ├─[249]: 1\n",
       "│ ├─[:,20]: SparseList (0) [1:1000]\n",
       "│ │ ├─[26]: 1\n",
       "│ │ ⋮\n",
       "│ ├─[:,68]: SparseList (0) [1:1000]\n",
       "│ │ ├─[928]: 1\n",
       "│ ├─[:,78]: SparseList (0) [1:1000]\n",
       "│ │ ├─[341]: 1\n",
       "├─[:,:,100]: SparseList (0) [:,1:100]\n",
       "│ ├─[:,20]: SparseList (0) [1:1000]\n",
       "│ │ ├─[181]: 1\n",
       "│ ├─[:,38]: SparseList (0) [1:1000]\n",
       "│ │ ├─[738]: 1\n",
       "│ │ ⋮\n",
       "│ ├─[:,75]: SparseList (0) [1:1000]\n",
       "│ │ ├─[357]: 1\n",
       "│ ├─[:,84]: SparseList (0) [1:1000]\n",
       "│ │ ├─[548]: 1"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniform_fiber([num_nodes, height, width], 1.0/height/width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tuple{Int64, Int64, Int64}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(Tuple([num_nodes, height, width]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.3",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
