{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spartan (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Finch\n",
    "using SparseArrays\n",
    "using Metatheory\n",
    "using Metatheory.EGraphs\n",
    "using TermInterface\n",
    "using PrettyPrinting\n",
    "include(\"../Source/Spartan.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Optimized) Expression: \n",
      "quote\n",
      "    ReduceDim(\n",
      "        +,\n",
      "        Set([\"i\"]),\n",
      "        ReduceDim(\n",
      "            +,\n",
      "            Set([\"l\"]),\n",
      "            MapJoin(\n",
      "                *,\n",
      "                InputTensor(\"B\", TensorStats(Set([\"j\", \"l\"]), Dict(\"j\" => 1000, \"l\" => 1000), 100000.0, 0.0), nothing),\n",
      "                MapJoin(\n",
      "                    *,\n",
      "                    InputTensor(\"A\", TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 100000.0, 0.0), nothing),\n",
      "                    InputTensor(\"A\", TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 100000.0, 0.0), nothing)))))\n",
      "end\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "Kernel: OperatorExpr(*, t_custom_op, InputTensorKernel[InputTensorKernel(\"A\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0)), InputTensorKernel(\"B\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0))])\n",
      "Expected Output Tensor Size: 10000.000000000002\n",
      "Output Tensor Size: 95129\n",
      "3\n",
      "Kernel: OperatorExpr(*, t_custom_op, InputTensorKernel[InputTensorKernel(\"A\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0)), InputTensorKernel(\"B\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0))])\n",
      "Expected Output Tensor Size: 1.0000000000000002e6\n",
      "Output Tensor Size: 9054244\n",
      "2\n",
      "Kernel: AggregateExpr(+, t_custom_agg, [\"l\"], InputTensorKernel(\"A\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0)))\n",
      "Expected Output Tensor Size: 632304.5752290363\n",
      "Output Tensor Size: 95129\n",
      "1\n",
      "Kernel: AggregateExpr(+, t_custom_agg, [\"i\"], InputTensorKernel(\"A\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0)))\n",
      "Expected Output Tensor Size: 1000.0\n",
      "Output Tensor Size: 1000\n",
      "Time to Execute: 7.899621162\n",
      "SaturationReport\n",
      "=================\n",
      "\tStop Reason: saturated\n",
      "\tIterations: 6\n",
      "\tEGraph Size: 18 eclasses, 48 nodes\n",
      "\u001b[0m\u001b[1m ────────────────────────────────────────────────────────────────────\u001b[22m\n",
      "\u001b[0m\u001b[1m                   \u001b[22m         Time                    Allocations      \n",
      "                   ───────────────────────   ────────────────────────\n",
      " Tot / % measured:     35.4ms /  99.7%           2.53MiB /  99.8%    \n",
      "\n",
      " Section   ncalls     time    %tot     avg     alloc    %tot      avg\n",
      " ────────────────────────────────────────────────────────────────────\n",
      " Apply          6   32.1ms   91.1%  5.35ms   1.22MiB   48.2%   208KiB\n",
      " Search         6   2.13ms    6.0%   355μs   1.08MiB   42.6%   184KiB\n",
      "   1            6    235μs    0.7%  39.2μs   51.7KiB    2.0%  8.62KiB\n",
      "   5            6    226μs    0.6%  37.7μs    137KiB    5.3%  22.8KiB\n",
      "   6            6    210μs    0.6%  35.1μs    112KiB    4.3%  18.7KiB\n",
      "   3            6    194μs    0.5%  32.3μs    110KiB    4.3%  18.4KiB\n",
      "   4            6    182μs    0.5%  30.3μs   75.9KiB    2.9%  12.6KiB\n",
      "   12           6    176μs    0.5%  29.3μs    100KiB    3.9%  16.7KiB\n",
      "   9            6    171μs    0.5%  28.6μs    111KiB    4.3%  18.5KiB\n",
      "   11           6    166μs    0.5%  27.7μs    117KiB    4.5%  19.5KiB\n",
      "   8            6    142μs    0.4%  23.6μs   80.5KiB    3.1%  13.4KiB\n",
      "   10           6    134μs    0.4%  22.4μs   76.9KiB    3.0%  12.8KiB\n",
      "   2            6   96.4μs    0.3%  16.1μs   43.6KiB    1.7%  7.27KiB\n",
      "   13           6   83.2μs    0.2%  13.9μs   35.7KiB    1.4%  5.94KiB\n",
      "   7            6   79.8μs    0.2%  13.3μs   34.5KiB    1.3%  5.75KiB\n",
      " Rebuild        6    988μs    2.8%   165μs    236KiB    9.1%  39.4KiB\n",
      "\u001b[0m\u001b[1m ────────────────────────────────────────────────────────────────────\u001b[22m\n",
      "\n",
      "(Optimized) Expression: \n",
      "quote\n",
      "    MapJoin(\n",
      "        *,\n",
      "        ReduceDim(\n",
      "            +,\n",
      "            Set([\"l\"]),\n",
      "            InputTensor(\"B\", TensorStats(Set([\"j\", \"l\"]), Dict(\"j\" => 1000, \"l\" => 1000), 100000.0, 0.0), MapJoin(*, InputTensor(#= circular reference @-2 =#), MapJoin(*, InputTensor(\"A\", TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 100000.0, 0.0), MapJoin(#= circular reference @-2 =#)), InputTensor(\"A\", TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 100000.0, 0.0), MapJoin(#= circular reference @-2 =#)), TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 10000.000000000002, 0.0), MapJoin(#= circular reference @-2 =#)), TensorStats(Set([\"j\", \"l\", \"i\"]), Dict(\"j\" => 1000, \"l\" => 1000, \"i\" => 1000), 1.0000000000000002e6, 0.0), ReduceDim(+, Set([\"l\"]), MapJoin(#= circular reference @-2 =#), TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 632304.5752290363, 0.0), ReduceDim(+, Set([\"i\"]), ReduceDim(#= circular reference @-2 =#), TensorStats(Set([\"j\"]), Dict(\"j\" => 1000), 1000.0, 0.0), nothing))))),\n",
      "        ReduceDim(\n",
      "            +,\n",
      "            Set([\"i\"]),\n",
      "            MapJoin(\n",
      "                ^,\n",
      "                InputTensor(\"A\", TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 100000.0, 0.0), MapJoin(*, InputTensor(#= circular reference @-2 =#), InputTensor(#= circular reference @-2 =#), TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 10000.000000000002, 0.0), MapJoin(*, InputTensor(\"B\", TensorStats(Set([\"j\", \"l\"]), Dict(\"j\" => 1000, \"l\" => 1000), 100000.0, 0.0), MapJoin(#= circular reference @-2 =#)), MapJoin(#= circular reference @-2 =#), TensorStats(Set([\"j\", \"l\", \"i\"]), Dict(\"j\" => 1000, \"l\" => 1000, \"i\" => 1000), 1.0000000000000002e6, 0.0), ReduceDim(+, Set([\"l\"]), MapJoin(#= circular reference @-2 =#), TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 632304.5752290363, 0.0), ReduceDim(+, Set([\"i\"]), ReduceDim(#= circular reference @-2 =#), TensorStats(Set([\"j\"]), Dict(\"j\" => 1000), 1000.0, 0.0), nothing))))),\n",
      "                2)))\n",
      "end\n",
      "1\n",
      "2\n",
      "3\n",
      "3\n",
      "Kernel: OperatorExpr(^, t_custom_op, InputTensorKernel[InputTensorKernel(\"A\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0)), InputTensorKernel(\"B\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0))])\n",
      "Expected Output Tensor Size: 100000.0\n",
      "Output Tensor Size: 95129\n",
      "2\n",
      "Kernel: AggregateExpr(+, t_custom_agg, [\"i\"], InputTensorKernel(\"A\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0)))\n",
      "Expected Output Tensor Size: 1000.0\n",
      "Output Tensor Size: 1000\n",
      "2\n",
      "2\n",
      "Kernel: AggregateExpr(+, t_custom_agg, [\"l\"], InputTensorKernel(\"A\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0)))\n",
      "Expected Output Tensor Size: 1000.0\n",
      "Output Tensor Size: 1000\n",
      "1\n",
      "Kernel: OperatorExpr(*, t_custom_op, InputTensorKernel[InputTensorKernel(\"A\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0)), InputTensorKernel(\"B\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0))])\n",
      "Expected Output Tensor Size: 1000.0\n",
      "Output Tensor Size: 1000\n",
      "Time to Execute: 0.575629909\n",
      "Is Correct?: true\n"
     ]
    }
   ],
   "source": [
    "is = Set([\"i\"])\n",
    "ls = Set([\"l\"])\n",
    "a_N = 100000\n",
    "a_indices = Set([\"i\", \"j\"])\n",
    "a_dimSizes = Dict(\"i\" => 1000, \"j\"=>1000)\n",
    "a = InputTensor(\"A\", TensorStats(a_indices, a_dimSizes, a_N, 0.0))\n",
    "A_fiber = dropdefaults(copyto!(@fiber(sl(sl(e(0.0)))), sparse(rand(1:a_dimSizes[\"i\"], a_N), rand(1:a_dimSizes[\"j\"], a_N), ones(a_N),  a_dimSizes[\"i\"], a_dimSizes[\"j\"]))) # remove zeros\n",
    "b_indices = Set([\"j\", \"l\"])\n",
    "b_dimSizes = Dict(\"j\" => 1000, \"l\" => 1000)\n",
    "b_N = 100000\n",
    "b = InputTensor(\"B\", TensorStats(b_indices, b_dimSizes, b_N, 0.0))\n",
    "B_fiber = dropdefaults(copyto!(@fiber(sl(sl(e(0.0)))), sparse(rand(1:b_dimSizes[\"j\"], b_N),rand(1:b_dimSizes[\"l\"], b_N), ones(b_N),b_dimSizes[\"j\"],  b_dimSizes[\"l\"])))\n",
    "input_tensor_dict = Dict(\"A\" => A_fiber, \"B\" => B_fiber)\n",
    "\n",
    "# Sum_i Sum_l B[j,l]*A[i,j]*A[i,j]\n",
    "output_tensor_1 = spartan(:(ReduceDim($+, $is, ReduceDim($+, $ls, MapJoin($*, $b, MapJoin($*, $a, $a))))), input_tensor_dict, verbose=true, optimize=false)\n",
    "#println(output_tensor)\n",
    "\n",
    "# (Sum_l B[j,l])*(Sum_i A[i,j] * A[i,j])\n",
    "output_tensor_2 = spartan(:(ReduceDim($+, $is, ReduceDim($+, $ls, MapJoin($*, $b, MapJoin($*, $a, $a))))), input_tensor_dict, verbose=true, optimize=true)\n",
    "#println(output_tensor)\n",
    "\n",
    "println(\"Is Correct?: \", output_tensor_1 == output_tensor_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Optimized) Expression: \n",
      "quote\n",
      "    ReduceDim(\n",
      "        +,\n",
      "        Set([\"i\"]),\n",
      "        ReduceDim(\n",
      "            +,\n",
      "            Set([\"j\"]),\n",
      "            MapJoin(\n",
      "                ^,\n",
      "                MapJoin(\n",
      "                    +,\n",
      "                    InputTensor(\"X\", TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 1000.0, 0.0), nothing),\n",
      "                    MapJoin(\n",
      "                        *,\n",
      "                        InputTensor(\"u\", TensorStats(Set([\"i\"]), Dict(\"i\" => 1000), 1000.0, 0.0), nothing),\n",
      "                        InputTensor(\"v\", TensorStats(Set([\"j\"]), Dict(\"j\" => 1000), 1000.0, 0.0), nothing))),\n",
      "                2)))\n",
      "end\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "5\n",
      "Kernel: OperatorExpr(*, t_custom_op, InputTensorKernel[InputTensorKernel(\"A\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0)), InputTensorKernel(\"B\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0))])\n",
      "Expected Output Tensor Size: 1.0e6\n",
      "Output Tensor Size: 1000000\n",
      "4\n",
      "Kernel: OperatorExpr(+, t_custom_op, InputTensorKernel[InputTensorKernel(\"A\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0)), InputTensorKernel(\"B\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0))])\n",
      "Expected Output Tensor Size: 1.0e6\n",
      "Output Tensor Size: 1000000\n",
      "3\n",
      "Kernel: OperatorExpr(^, t_custom_op, InputTensorKernel[InputTensorKernel(\"A\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0)), InputTensorKernel(\"B\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0))])\n",
      "Expected Output Tensor Size: 1.0e6\n",
      "Output Tensor Size: 1000000\n",
      "2\n",
      "Kernel: AggregateExpr(+, t_custom_agg, [\"j\"], InputTensorKernel(\"A\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0)))\n",
      "Expected Output Tensor Size: 1000.0\n",
      "Output Tensor Size: 1000\n",
      "1\n",
      "Kernel: AggregateExpr(+, t_custom_agg, [\"i\"], InputTensorKernel(\"A\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0)))\n",
      "Expected Output Tensor Size: 1.0\n",
      "Output Tensor Size: 1\n",
      "Time to Execute: 1.160762948\n",
      "SaturationReport\n",
      "=================\n",
      "\tStop Reason: saturated\n",
      "\tIterations: 17\n",
      "\tEGraph Size: 86 eclasses, 717 nodes\n",
      "\u001b[0m\u001b[1m ────────────────────────────────────────────────────────────────────\u001b[22m\n",
      "\u001b[0m\u001b[1m                   \u001b[22m         Time                    Allocations      \n",
      "                   ───────────────────────   ────────────────────────\n",
      " Tot / % measured:      423ms /  74.2%           61.3MiB /  97.3%    \n",
      "\n",
      " Section   ncalls     time    %tot     avg     alloc    %tot      avg\n",
      " ────────────────────────────────────────────────────────────────────\n",
      " Apply         17    259ms   82.6%  15.3ms   25.5MiB   42.7%  1.50MiB\n",
      " Search        17   38.1ms   12.1%  2.24ms   27.8MiB   46.7%  1.64MiB\n",
      "   9           17   7.33ms    2.3%   431μs   5.67MiB    9.5%   341KiB\n",
      "   6           17   5.22ms    1.7%   307μs   4.18MiB    7.0%   252KiB\n",
      "   4           17   5.07ms    1.6%   298μs   3.67MiB    6.1%   221KiB\n",
      "   5           17   4.28ms    1.4%   252μs   3.09MiB    5.2%   186KiB\n",
      "   3           17   2.66ms    0.8%   156μs   2.08MiB    3.5%   125KiB\n",
      "   7           17   2.61ms    0.8%   154μs   1.94MiB    3.2%   117KiB\n",
      "   12          17   2.05ms    0.7%   120μs   1.30MiB    2.2%  78.3KiB\n",
      "   11          17   1.99ms    0.6%   117μs   1.56MiB    2.6%  93.9KiB\n",
      "   1           17   1.73ms    0.6%   102μs   1.02MiB    1.7%  61.5KiB\n",
      "   8           17   1.67ms    0.5%  98.2μs   1.12MiB    1.9%  67.3KiB\n",
      "   10          17   1.27ms    0.4%  74.8μs    880KiB    1.4%  51.8KiB\n",
      "   2           17   1.11ms    0.4%  65.2μs    796KiB    1.3%  46.8KiB\n",
      "   13          17   1.02ms    0.3%  59.8μs    566KiB    0.9%  33.3KiB\n",
      " Rebuild       17   16.6ms    5.3%   978μs   6.33MiB   10.6%   382KiB\n",
      "\u001b[0m\u001b[1m ────────────────────────────────────────────────────────────────────\u001b[22m\n",
      "\n",
      "(Optimized) Expression: \n",
      "quote\n",
      "    MapJoin(\n",
      "        +,\n",
      "        MapJoin(\n",
      "            +,\n",
      "            MapJoin(\n",
      "                *,\n",
      "                ReduceDim(\n",
      "                    +,\n",
      "                    Set([\"i\"]),\n",
      "                    MapJoin(\n",
      "                        ^,\n",
      "                        InputTensor(\"u\", TensorStats(Set([\"i\"]), Dict(\"i\" => 1000), 1000.0, 0.0), MapJoin(*, InputTensor(#= circular reference @-2 =#), InputTensor(\"v\", TensorStats(Set([\"j\"]), Dict(\"j\" => 1000), 1000.0, 0.0), MapJoin(#= circular reference @-2 =#)), TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 1.0e6, 0.0), MapJoin(+, InputTensor(\"X\", TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 1000.0, 0.0), MapJoin(#= circular reference @-2 =#)), MapJoin(#= circular reference @-2 =#), TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 1.0e6, 0.0), MapJoin(^, MapJoin(#= circular reference @-2 =#), Scalar(2, TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 2), MapJoin(#= circular reference @-2 =#)), TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 1.0e6, 0.0), ReduceDim(+, Set([\"j\"]), MapJoin(#= circular reference @-2 =#), TensorStats(Set([\"i\"]), Dict(\"i\" => 1000), 1000.0, 0.0), ReduceDim(+, Set([\"i\"]), ReduceDim(#= circular reference @-2 =#), TensorStats(Set{String}(), Dict{String, Int64}(), 1.0, 0.0), nothing)))))),\n",
      "                        2)),\n",
      "                ReduceDim(\n",
      "                    +,\n",
      "                    Set([\"j\"]),\n",
      "                    MapJoin(\n",
      "                        ^,\n",
      "                        InputTensor(\"v\", TensorStats(Set([\"j\"]), Dict(\"j\" => 1000), 1000.0, 0.0), MapJoin(*, InputTensor(\"u\", TensorStats(Set([\"i\"]), Dict(\"i\" => 1000), 1000.0, 0.0), MapJoin(#= circular reference @-2 =#)), InputTensor(#= circular reference @-2 =#), TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 1.0e6, 0.0), MapJoin(+, InputTensor(\"X\", TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 1000.0, 0.0), MapJoin(#= circular reference @-2 =#)), MapJoin(#= circular reference @-2 =#), TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 1.0e6, 0.0), MapJoin(^, MapJoin(#= circular reference @-2 =#), Scalar(2, TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 2), MapJoin(#= circular reference @-2 =#)), TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 1.0e6, 0.0), ReduceDim(+, Set([\"j\"]), MapJoin(#= circular reference @-2 =#), TensorStats(Set([\"i\"]), Dict(\"i\" => 1000), 1000.0, 0.0), ReduceDim(+, Set([\"i\"]), ReduceDim(#= circular reference @-2 =#), TensorStats(Set{String}(), Dict{String, Int64}(), 1.0, 0.0), nothing)))))),\n",
      "                        2))),\n",
      "            ReduceDim(\n",
      "                +,\n",
      "                Set([\"j\"]),\n",
      "                ReduceDim(\n",
      "                    +,\n",
      "                    Set([\"i\"]),\n",
      "                    MapJoin(\n",
      "                        *,\n",
      "                        MapJoin(\n",
      "                            *,\n",
      "                            InputTensor(\"X\", TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 1000.0, 0.0), MapJoin(+, InputTensor(#= circular reference @-2 =#), MapJoin(*, InputTensor(\"u\", TensorStats(Set([\"i\"]), Dict(\"i\" => 1000), 1000.0, 0.0), MapJoin(#= circular reference @-2 =#)), InputTensor(\"v\", TensorStats(Set([\"j\"]), Dict(\"j\" => 1000), 1000.0, 0.0), MapJoin(#= circular reference @-2 =#)), TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 1.0e6, 0.0), MapJoin(#= circular reference @-2 =#)), TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 1.0e6, 0.0), MapJoin(^, MapJoin(#= circular reference @-2 =#), Scalar(2, TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 2), MapJoin(#= circular reference @-2 =#)), TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 1.0e6, 0.0), ReduceDim(+, Set([\"j\"]), MapJoin(#= circular reference @-2 =#), TensorStats(Set([\"i\"]), Dict(\"i\" => 1000), 1000.0, 0.0), ReduceDim(+, Set([\"i\"]), ReduceDim(#= circular reference @-2 =#), TensorStats(Set{String}(), Dict{String, Int64}(), 1.0, 0.0), nothing))))),\n",
      "                            InputTensor(\"v\", TensorStats(Set([\"j\"]), Dict(\"j\" => 1000), 1000.0, 0.0), MapJoin(*, InputTensor(\"u\", TensorStats(Set([\"i\"]), Dict(\"i\" => 1000), 1000.0, 0.0), MapJoin(#= circular reference @-2 =#)), InputTensor(#= circular reference @-2 =#), TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 1.0e6, 0.0), MapJoin(+, InputTensor(\"X\", TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 1000.0, 0.0), MapJoin(#= circular reference @-2 =#)), MapJoin(#= circular reference @-2 =#), TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 1.0e6, 0.0), MapJoin(^, MapJoin(#= circular reference @-2 =#), Scalar(2, TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 2), MapJoin(#= circular reference @-2 =#)), TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 1.0e6, 0.0), ReduceDim(+, Set([\"j\"]), MapJoin(#= circular reference @-2 =#), TensorStats(Set([\"i\"]), Dict(\"i\" => 1000), 1000.0, 0.0), ReduceDim(+, Set([\"i\"]), ReduceDim(#= circular reference @-2 =#), TensorStats(Set{String}(), Dict{String, Int64}(), 1.0, 0.0), nothing))))))),\n",
      "                        InputTensor(\"u\", TensorStats(Set([\"i\"]), Dict(\"i\" => 1000), 1000.0, 0.0), MapJoin(*, InputTensor(#= circular reference @-2 =#), InputTensor(\"v\", TensorStats(Set([\"j\"]), Dict(\"j\" => 1000), 1000.0, 0.0), MapJoin(#= circular reference @-2 =#)), TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 1.0e6, 0.0), MapJoin(+, InputTensor(\"X\", TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 1000.0, 0.0), MapJoin(#= circular reference @-2 =#)), MapJoin(#= circular reference @-2 =#), TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 1.0e6, 0.0), MapJoin(^, MapJoin(#= circular reference @-2 =#), Scalar(2, TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 2), MapJoin(#= circular reference @-2 =#)), TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 1.0e6, 0.0), ReduceDim(+, Set([\"j\"]), MapJoin(#= circular reference @-2 =#), TensorStats(Set([\"i\"]), Dict(\"i\" => 1000), 1000.0, 0.0), ReduceDim(+, Set([\"i\"]), ReduceDim(#= circular reference @-2 =#), TensorStats(Set{String}(), Dict{String, Int64}(), 1.0, 0.0), nothing)))))))))),\n",
      "        MapJoin(\n",
      "            +,\n",
      "            ReduceDim(\n",
      "                +,\n",
      "                Set([\"j\"]),\n",
      "                ReduceDim(\n",
      "                    +,\n",
      "                    Set([\"i\"]),\n",
      "                    MapJoin(\n",
      "                        *,\n",
      "                        MapJoin(\n",
      "                            *,\n",
      "                            InputTensor(\"X\", TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 1000.0, 0.0), MapJoin(+, InputTensor(#= circular reference @-2 =#), MapJoin(*, InputTensor(\"u\", TensorStats(Set([\"i\"]), Dict(\"i\" => 1000), 1000.0, 0.0), MapJoin(#= circular reference @-2 =#)), InputTensor(\"v\", TensorStats(Set([\"j\"]), Dict(\"j\" => 1000), 1000.0, 0.0), MapJoin(#= circular reference @-2 =#)), TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 1.0e6, 0.0), MapJoin(#= circular reference @-2 =#)), TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 1.0e6, 0.0), MapJoin(^, MapJoin(#= circular reference @-2 =#), Scalar(2, TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 2), MapJoin(#= circular reference @-2 =#)), TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 1.0e6, 0.0), ReduceDim(+, Set([\"j\"]), MapJoin(#= circular reference @-2 =#), TensorStats(Set([\"i\"]), Dict(\"i\" => 1000), 1000.0, 0.0), ReduceDim(+, Set([\"i\"]), ReduceDim(#= circular reference @-2 =#), TensorStats(Set{String}(), Dict{String, Int64}(), 1.0, 0.0), nothing))))),\n",
      "                            InputTensor(\"v\", TensorStats(Set([\"j\"]), Dict(\"j\" => 1000), 1000.0, 0.0), MapJoin(*, InputTensor(\"u\", TensorStats(Set([\"i\"]), Dict(\"i\" => 1000), 1000.0, 0.0), MapJoin(#= circular reference @-2 =#)), InputTensor(#= circular reference @-2 =#), TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 1.0e6, 0.0), MapJoin(+, InputTensor(\"X\", TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 1000.0, 0.0), MapJoin(#= circular reference @-2 =#)), MapJoin(#= circular reference @-2 =#), TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 1.0e6, 0.0), MapJoin(^, MapJoin(#= circular reference @-2 =#), Scalar(2, TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 2), MapJoin(#= circular reference @-2 =#)), TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 1.0e6, 0.0), ReduceDim(+, Set([\"j\"]), MapJoin(#= circular reference @-2 =#), TensorStats(Set([\"i\"]), Dict(\"i\" => 1000), 1000.0, 0.0), ReduceDim(+, Set([\"i\"]), ReduceDim(#= circular reference @-2 =#), TensorStats(Set{String}(), Dict{String, Int64}(), 1.0, 0.0), nothing))))))),\n",
      "                        InputTensor(\"u\", TensorStats(Set([\"i\"]), Dict(\"i\" => 1000), 1000.0, 0.0), MapJoin(*, InputTensor(#= circular reference @-2 =#), InputTensor(\"v\", TensorStats(Set([\"j\"]), Dict(\"j\" => 1000), 1000.0, 0.0), MapJoin(#= circular reference @-2 =#)), TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 1.0e6, 0.0), MapJoin(+, InputTensor(\"X\", TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 1000.0, 0.0), MapJoin(#= circular reference @-2 =#)), MapJoin(#= circular reference @-2 =#), TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 1.0e6, 0.0), MapJoin(^, MapJoin(#= circular reference @-2 =#), Scalar(2, TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 2), MapJoin(#= circular reference @-2 =#)), TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 1.0e6, 0.0), ReduceDim(+, Set([\"j\"]), MapJoin(#= circular reference @-2 =#), TensorStats(Set([\"i\"]), Dict(\"i\" => 1000), 1000.0, 0.0), ReduceDim(+, Set([\"i\"]), ReduceDim(#= circular reference @-2 =#), TensorStats(Set{String}(), Dict{String, Int64}(), 1.0, 0.0), nothing))))))))),\n",
      "            ReduceDim(\n",
      "                +,\n",
      "                Set([\"j\"]),\n",
      "                ReduceDim(\n",
      "                    +,\n",
      "                    Set([\"i\"]),\n",
      "                    MapJoin(\n",
      "                        ^,\n",
      "                        InputTensor(\"X\", TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 1000.0, 0.0), MapJoin(+, InputTensor(#= circular reference @-2 =#), MapJoin(*, InputTensor(\"u\", TensorStats(Set([\"i\"]), Dict(\"i\" => 1000), 1000.0, 0.0), MapJoin(#= circular reference @-2 =#)), InputTensor(\"v\", TensorStats(Set([\"j\"]), Dict(\"j\" => 1000), 1000.0, 0.0), MapJoin(#= circular reference @-2 =#)), TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 1.0e6, 0.0), MapJoin(#= circular reference @-2 =#)), TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 1.0e6, 0.0), MapJoin(^, MapJoin(#= circular reference @-2 =#), Scalar(2, TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 2), MapJoin(#= circular reference @-2 =#)), TensorStats(Set([\"j\", \"i\"]), Dict(\"j\" => 1000, \"i\" => 1000), 1.0e6, 0.0), ReduceDim(+, Set([\"j\"]), MapJoin(#= circular reference @-2 =#), TensorStats(Set([\"i\"]), Dict(\"i\" => 1000), 1000.0, 0.0), ReduceDim(+, Set([\"i\"]), ReduceDim(#= circular reference @-2 =#), TensorStats(Set{String}(), Dict{String, Int64}(), 1.0, 0.0), nothing))))),\n",
      "                        2)))))\n",
      "end\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "5\n",
      "Kernel: OperatorExpr(^, t_custom_op, InputTensorKernel[InputTensorKernel(\"A\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0)), InputTensorKernel(\"B\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0))])\n",
      "Expected Output Tensor Size: 1000.0\n",
      "Output Tensor Size: 1000\n",
      "4\n",
      "Kernel: AggregateExpr(+, t_custom_agg, [\"i\"], InputTensorKernel(\"A\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0)))\n",
      "Expected Output Tensor Size: 632.3045752290362\n",
      "Output Tensor Size: 664\n",
      "3\n",
      "Kernel: AggregateExpr(+, t_custom_agg, [\"j\"], InputTensorKernel(\"A\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0)))\n",
      "Expected Output Tensor Size: 1.0\n",
      "Output Tensor Size: 1\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "6\n",
      "Kernel: OperatorExpr(*, t_custom_op, InputTensorKernel[InputTensorKernel(\"A\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0)), InputTensorKernel(\"B\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0))])\n",
      "Expected Output Tensor Size: 1000.0\n",
      "Output Tensor Size: 1000\n",
      "5\n",
      "Kernel: OperatorExpr(*, t_custom_op, InputTensorKernel[InputTensorKernel(\"A\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0)), InputTensorKernel(\"B\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0))])\n",
      "Expected Output Tensor Size: 1000.0\n",
      "Output Tensor Size: 1000\n",
      "4\n",
      "Kernel: AggregateExpr(+, t_custom_agg, [\"i\"], InputTensorKernel(\"A\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0)))\n",
      "Expected Output Tensor Size: 632.3045752290362\n",
      "Output Tensor Size: 664\n",
      "3\n",
      "Kernel: AggregateExpr(+, t_custom_agg, [\"j\"], InputTensorKernel(\"A\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0)))\n",
      "Expected Output Tensor Size: 1.0\n",
      "Output Tensor Size: 1\n",
      "2\n",
      "Kernel: OperatorExpr(+, t_custom_op, InputTensorKernel[InputTensorKernel(\"A\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0)), InputTensorKernel(\"B\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0))])\n",
      "Expected Output Tensor Size: 1.0\n",
      "Output Tensor Size: 1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "6\n",
      "Kernel: OperatorExpr(*, t_custom_op, InputTensorKernel[InputTensorKernel(\"A\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0)), InputTensorKernel(\"B\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0))])\n",
      "Expected Output Tensor Size: 1000.0\n",
      "Output Tensor Size: 1000\n",
      "5\n",
      "Kernel: OperatorExpr(*, t_custom_op, InputTensorKernel[InputTensorKernel(\"A\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0)), InputTensorKernel(\"B\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0))])\n",
      "Expected Output Tensor Size: 1000.0\n",
      "Output Tensor Size: 1000\n",
      "4\n",
      "Kernel: AggregateExpr(+, t_custom_agg, [\"i\"], InputTensorKernel(\"A\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0)))\n",
      "Expected Output Tensor Size: 632.3045752290362\n",
      "Output Tensor Size: 664\n",
      "3\n",
      "Kernel: AggregateExpr(+, t_custom_agg, [\"j\"], InputTensorKernel(\"A\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0)))\n",
      "Expected Output Tensor Size: 1.0\n",
      "Output Tensor Size: 1\n",
      "3\n",
      "4\n",
      "5\n",
      "5\n",
      "Kernel: OperatorExpr(^, t_custom_op, InputTensorKernel[InputTensorKernel(\"A\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0)), InputTensorKernel(\"B\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0))])\n",
      "Expected Output Tensor Size: 1000.0\n",
      "Output Tensor Size: 1000\n",
      "4\n",
      "Kernel: AggregateExpr(+, t_custom_agg, [\"j\"], InputTensorKernel(\"A\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0)))\n",
      "Expected Output Tensor Size: 1.0\n",
      "Output Tensor Size: 1\n",
      "4\n",
      "5\n",
      "5\n",
      "Kernel: OperatorExpr(^, t_custom_op, InputTensorKernel[InputTensorKernel(\"A\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0)), InputTensorKernel(\"B\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0))])\n",
      "Expected Output Tensor Size: 1000.0\n",
      "Output Tensor Size: 1000\n",
      "4\n",
      "Kernel: AggregateExpr(+, t_custom_agg, [\"i\"], InputTensorKernel(\"A\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0)))\n",
      "Expected Output Tensor Size: 1.0\n",
      "Output Tensor Size: 1\n",
      "3\n",
      "Kernel: OperatorExpr(*, t_custom_op, InputTensorKernel[InputTensorKernel(\"A\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0)), InputTensorKernel(\"B\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0))])\n",
      "Expected Output Tensor Size: 1.0\n",
      "Output Tensor Size: 1\n",
      "2\n",
      "Kernel: OperatorExpr(+, t_custom_op, InputTensorKernel[InputTensorKernel(\"A\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0)), InputTensorKernel(\"B\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0))])\n",
      "Expected Output Tensor Size: 1.0\n",
      "Output Tensor Size: 1\n",
      "1\n",
      "Kernel: OperatorExpr(+, t_custom_op, InputTensorKernel[InputTensorKernel(\"A\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0)), InputTensorKernel(\"B\", TensorStats(Set{String}(), Dict{String, Int64}(), 0.0, 0))])\n",
      "Expected Output Tensor Size: 1.0\n",
      "Output Tensor Size: 1\n",
      "Time to Execute: 0.116952347\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.003e6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is = Set([\"i\"])\n",
    "js = Set([\"j\"])\n",
    "N = 1000\n",
    "x_N = 1000\n",
    "x_indices = Set([\"i\", \"j\"])\n",
    "x_dimSizes = Dict(\"i\" => N, \"j\"=>N)\n",
    "X = InputTensor(\"X\", TensorStats(x_indices, x_dimSizes, x_N, 0.0))\n",
    "X_fiber = dropdefaults(copyto!(@fiber(sl(sl(e(0.0)))), sparse(rand(1:x_dimSizes[\"j\"], x_N), rand(1:x_dimSizes[\"i\"], x_N), ones(x_N), x_dimSizes[\"j\"], x_dimSizes[\"i\"]))) # remove zeros\n",
    "u_N = N\n",
    "u_indices = Set([\"i\"])\n",
    "u_dimSizes = Dict(\"i\" => N)\n",
    "u = InputTensor(\"u\", TensorStats(u_indices, u_dimSizes, u_dimSizes[\"i\"], 0.0))\n",
    "u_fiber = dropdefaults(copyto!(@fiber(sh{1}(e(0.0))), ones(u_N))) \n",
    "v_N = N\n",
    "v_indices = Set([\"j\"])\n",
    "v_dimSizes = Dict(\"j\" => N)\n",
    "v = InputTensor(\"v\", TensorStats(v_indices, v_dimSizes, v_dimSizes[\"j\"], 0.0))\n",
    "v_fiber = dropdefaults(copyto!(@fiber(sh{1}(e(0.0))), ones(v_N)))\n",
    "input_tensor_dict = Dict(\"X\" => X_fiber, \"u\" => u_fiber, \"v\" => v_fiber)\n",
    "\n",
    "# Sum_i Sum_l B[j,l]*A[i,j]*A[i,j]\n",
    "output_tensor_1 = spartan(:(ReduceDim($+, $is, ReduceDim($+, $js, MapJoin($^, MapJoin($+, $X, MapJoin($*, $u, $v)), 2)))), input_tensor_dict, verbose=true, optimize=false)\n",
    "\n",
    "# (Sum_l B[j,l])*(Sum_i A[i,j] * A[i,j])\n",
    "output_tensor_2 = spartan(:(ReduceDim($+, $is, ReduceDim($+, $js, MapJoin($^, MapJoin($+, $X, MapJoin($*, $u, $v)), 2)))), input_tensor_dict, verbose=true, optimize=true)\n",
    "\n",
    "println(\"Is Correct?: \", output_tensor_1 == output_tensor_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sequence_instance(declare_instance(variable_instance(:t, t), literal_instance(0)), loop_instance(index_instance(:j), loop_instance(index_instance(:l), loop_instance(index_instance(:i), assign_instance(access_instance(variable_instance(:t, t), updater_instance(create_instance()), index_instance(:l), index_instance(:j)), variable_instance(:+, +), call_instance(variable_instance(:*, *), access_instance(variable_instance(:A_fiber, A_fiber), reader_instance(), index_instance(:i), index_instance(:j)), access_instance(variable_instance(:B_fiber, B_fiber), reader_instance(), index_instance(:j), index_instance(:l))))))))\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Finch\n",
    "t = @fiber(sl(sl(e(0.0))))\n",
    "Finch.@finch_program_instance (t .= 0; @loop j l i t[l, j] += A_fiber[i,j] * B_fiber[j,l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sequence_instance(declare_instance(variable_instance(:C, C), literal_instance(0)), loop_instance(index_instance(:i), loop_instance(index_instance(:j), assign_instance(access_instance(variable_instance(:C, C), updater_instance(create_instance()), index_instance(:j), index_instance(:i)), literal_instance(Finch.FinchNotation.InitWriter{0.0}()), call_instance(variable_instance(:*, *), access_instance(variable_instance(:A_fiber, A_fiber), reader_instance(), index_instance(:j), index_instance(:i)), access_instance(variable_instance(:B_fiber, B_fiber), reader_instance(), index_instance(:j), index_instance(:i)))))))\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = @fiber(sl(sl(e(0.0))))\n",
    "prgm = Finch.@finch_program_instance (C .= 0; @loop i j C[j, i] = A_fiber[j, i] * B_fiber[j, i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: a_dimSizes not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: a_dimSizes not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ some.jl:141",
      " [2] eval",
      "   @ ./boot.jl:368 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1428"
     ]
    }
   ],
   "source": [
    "N=10000\n",
    "A_fiber = dropdefaults(copyto!(@fiber(sl(sl(e(0.0)))), sparse(rand(1:a_dimSizes[\"j\"], N), rand(1:a_dimSizes[\"i\"], N), ones(N), a_dimSizes[\"j\"], a_dimSizes[\"i\"]))) # remove zeros\n",
    "D = @fiber(sl(sl(sl(e(0.0)))))\n",
    "@finch (D.=0; @loop l j i D[i,j,l] = A_fiber[i,j] * A_fiber[j,l])\n",
    "countstored(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(C = Fiber(SparseList{Int64, Int64}(SparseList{Int64, Int64}(SparseList{Int64, Int64}(Element{0.0, Float64}([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]), 10000, [1, 3, 8, 12, 16, 19, 20, 21, 25, 29  …  9861, 9862, 9864, 9866, 9868, 9869, 9870, 9871, 9872, 9873], [419, 6391, 2441, 4892, 6866, 6954, 9064, 1897, 4702, 6455  …  9516, 8842, 9516, 7047, 9014, 5601, 5601, 5601, 7622, 7622]), 10000, [1, 2, 3, 5, 6, 7, 8, 11, 12, 15  …  6232, 6234, 6235, 6236, 6238, 6239, 6241, 6242, 6245, 6247], [5020, 3375, 1821, 5941, 8359, 2837, 9311, 3002, 5799, 8907  …  9465, 2800, 2383, 6452, 1180, 1514, 3318, 4554, 571, 6510]), 10000, [1, 3973], [2, 4, 6, 8, 9, 13, 15, 17, 19, 25  …  9969, 9970, 9974, 9975, 9982, 9983, 9985, 9986, 9998, 10000])),)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = @fiber(sl(sl(sl(e(0.0)))))\n",
    "@finch (C .= 0; @loop  l i j C[i, l, j] = D[i,j,l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = @fiber(sl(sl(e(0.0))))\n",
    "@finch (C .= 0; @loop  j i l C[i,j] += D[i,j,l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is = Set([\"i\"])\n",
    "ks = Set([\"k\"])\n",
    "a_indices = Set([\"i\", \"j\"])\n",
    "a_dimSizes = Dict(\"i\" => 1000, \"j\"=>100)\n",
    "a = InputTensor(TensorStats(a_indices, a_dimSizes, 100000, 0.0), \"A\")\n",
    "b_indices = Set([\"j\", \"k\"])\n",
    "b_dimSizes = Dict(\"j\" => 100, \"k\"=>1000)\n",
    "b = InputTensor(TensorStats(b_indices, b_dimSizes, 100000, 0.0), \"B\")\n",
    "c_indices = Set([\"j\", \"l\"])\n",
    "c_dimSizes = Dict(\"j\" => 100, \"l\" => 100)\n",
    "c = InputTensor(TensorStats(c_indices, c_dimSizes, 10000, 0.0), \"C\")\n",
    "\n",
    "# Sum_i Sum_k C[j,l] + B[j,k] * A[i,j]\n",
    "g= EGraph(:(reduceDim($+, $is, reduceDim($+, $ks, MapJoin($+, $c, MapJoin($*, $b, $a))))))\n",
    "analyze!(g, :TensorStatsAnalysis)\n",
    "params = SaturationParams(timeout=10, eclasslimit=4000)\n",
    "report = saturate!(g, basic_rewrites, params);\n",
    "\n",
    "# Results In:(Sum_k,i C[j,l]) + (Sum_k B[j,k]) * (Sum_i A[i,j])\n",
    "pprintln(extract!(g, simple_cardinality_cost_function))\n",
    "print(report)\n",
    "getdata(g[g.root], :TensorStatsAnalysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is = Set([\"i\"])\n",
    "js = Set([\"j\"])\n",
    "ks = Set([\"k\"])\n",
    "x_indices = Set([\"i\", \"j\"])\n",
    "x_dimSizes = Dict(\"i\" => 1000, \"j\"=>1000)\n",
    "x = InputTensor(TensorStats(x_indices, x_dimSizes, 100, 0.0), \"X\")\n",
    "u_indices = Set([\"i\", \"k\"])\n",
    "u_dimSizes = Dict(\"i\" => 1000, \"k\"=>10)\n",
    "u = InputTensor(TensorStats(u_indices, u_dimSizes, 10000, 0.0), \"U\")\n",
    "v_indices = Set([\"k\", \"j\"])\n",
    "v_dimSizes = Dict(\"k\" => 10, \"j\" => 1000)\n",
    "v = InputTensor(TensorStats(v_indices, v_dimSizes, 10000, 0.0), \"V\")\n",
    "\n",
    "# Sum_i Sum_k C[j,l] + B[j,k] * A[i,j]\n",
    "g= EGraph(:(reduceDim($+, $is, reduceDim($+, $js, mapScalar($^, MapJoin($+, $x, reduceDim($+, $ks, MapJoin($*, $u, $v))), $2)))))\n",
    "\n",
    "analyze!(g, :TensorStatsAnalysis)\n",
    "params = SaturationParams(timeout=100, eclasslimit=4000)\n",
    "report = saturate!(g, basic_rewrites, params);\n",
    "\n",
    "# Results In:(Sum_k,i C[j,l]) + (Sum_i B[j,k]) * (Sum_k A[i,j])\n",
    "pprintln(extract!(g, simple_cardinality_cost_function))\n",
    "print(report)\n",
    "getdata(g[g.root], :TensorStatsAnalysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "AssertionError: isempty(MERGES_BUF[])",
     "output_type": "error",
     "traceback": [
      "AssertionError: isempty(MERGES_BUF[])",
      "",
      "Stacktrace:",
      " [1] eqsat_apply!",
      "   @ ~/.julia/packages/Metatheory/6aio8/src/EGraphs/saturation.jl:216 [inlined]",
      " [2] macro expansion",
      "   @ ~/.julia/packages/TimerOutputs/RsWnF/src/TimerOutput.jl:237 [inlined]",
      " [3] eqsat_step!(g::EGraph, theory::Vector{AbstractRule}, curr_iter::Int64, scheduler::Metatheory.EGraphs.Schedulers.BackoffScheduler, params::SaturationParams, report::Metatheory.EGraphs.SaturationReport)",
      "   @ Metatheory.EGraphs ~/.julia/packages/Metatheory/6aio8/src/EGraphs/saturation.jl:272",
      " [4] saturate!(g::EGraph, theory::Vector{AbstractRule}, params::SaturationParams)",
      "   @ Metatheory.EGraphs ~/.julia/packages/Metatheory/6aio8/src/EGraphs/saturation.jl:302",
      " [5] top-level scope",
      "   @ In[11]:20",
      " [6] eval",
      "   @ ./boot.jl:368 [inlined]",
      " [7] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1428"
     ]
    }
   ],
   "source": [
    "is = Set([\"i\"])\n",
    "js = Set([\"j\"])\n",
    "ks = Set([\"k\"])\n",
    "tensors = []\n",
    "for i in 1:10\n",
    "    indices = Set([\"i_\" *  string(i), \"i_\" * string(i+1)])\n",
    "    dimSizes = Dict()\n",
    "    for index in indices\n",
    "        dimSizes[index] = 100\n",
    "    end\n",
    "    push!(tensors, InputTensor(\"A_\" * string(i), TensorStats(indices, dimSizes, 10000, 0.0)))\n",
    "end\n",
    "\n",
    "\n",
    "# Optimization w/cross products\n",
    "#g= EGraph(:(MapJoin($*, $(tensors[1]), MapJoin($*, $(tensors[2]), MapJoin($*, $(tensors[3]), MapJoin($*, $(tensors[4]), MapJoin($*, $(tensors[5]), MapJoin($*, $(tensors[6]), MapJoin($*, $(tensors[7]), MapJoin($*, $(tensors[8]), $(tensors[9])))))))))))\n",
    "g= EGraph(:(MapJoin($*, $(tensors[1]), MapJoin($*, $(tensors[2]), MapJoin($*, $(tensors[3]), MapJoin($*, $(tensors[4]), MapJoin($*, $(tensors[5]), MapJoin($*, $(tensors[6]), MapJoin($*, $(tensors[7]), $(tensors[8]))))))))))\n",
    "analyze!(g, :TensorStatsAnalysis)\n",
    "params = SaturationParams(timeout=10, eclasslimit=100000)\n",
    "report = saturate!(g, basic_rewrites, params);\n",
    "\n",
    "pprintln(extract!(g, simple_cardinality_cost_function))\n",
    "print(report)\n",
    "getdata(g[g.root], :TensorStatsAnalysis)\n",
    "\n",
    "\n",
    "\n",
    "# Optimization w/out cross-products\n",
    "#g= EGraph(:(MapJoin($*, $(tensors[1]), MapJoin($*, $(tensors[2]), MapJoin($*, $(tensors[3]), MapJoin($*, $(tensors[4]), MapJoin($*, $(tensors[5]), MapJoin($*, $(tensors[6]), MapJoin($*, $(tensors[7]), MapJoin($*, $(tensors[8]), $(tensors[9])))))))))))\n",
    "g= EGraph(:(MapJoin($*, $(tensors[1]), MapJoin($*, $(tensors[2]), MapJoin($*, $(tensors[3]), MapJoin($*, $(tensors[4]), MapJoin($*, $(tensors[5]), MapJoin($*, $(tensors[6]), MapJoin($*, $(tensors[7]), $(tensors[8]))))))))))\n",
    "analyze!(g, :TensorStatsAnalysis)\n",
    "params = SaturationParams(timeout=10, eclasslimit=100000)\n",
    "report = saturate!(g, basic_rewrites_2, params);\n",
    "\n",
    "pprintln(extract!(g, simple_cardinality_cost_function))\n",
    "print(report)\n",
    "getdata(g[g.root], :TensorStatsAnalysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63708"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.3",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
